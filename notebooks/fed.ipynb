{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc275f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "# !pip install tensorboard\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_state(seed=42069):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3675444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "\n",
    "def read_data(train_data_dir, test_data_dir=None):\n",
    "    '''parses data in given train and test data directories\n",
    "    assumes:\n",
    "    - the data in the input directories are .json files with \n",
    "        keys 'users' and 'user_data'\n",
    "    - the set of train set users is the same as the set of test set users\n",
    "    \n",
    "    Return:\n",
    "        clients: list of client ids\n",
    "        groups: list of group ids; empty list if none found\n",
    "        train_data: dictionary of train data\n",
    "        test_data: dictionary of test data\n",
    "    '''\n",
    "    group_ids = []\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    train_files = os.listdir(train_data_dir)\n",
    "    if 'train.json' in train_files:\n",
    "        with open(os.path.join(train_data_dir, 'train.json'), 'r') as f:\n",
    "            cdata = json.load(f)\n",
    "        if 'hierarchies' in cdata:\n",
    "            group_ids.extend(cdata['hierarchies'])\n",
    "        train_data.update(cdata['user_data'])\n",
    "    else:\n",
    "        train_files = [f for f in train_files if f.endswith('.json')]\n",
    "        for f in train_files:\n",
    "            file_path = os.path.join(train_data_dir,f)\n",
    "            with open(file_path, 'r') as inf:\n",
    "                cdata = json.load(inf)\n",
    "            if 'hierarchies' in cdata:\n",
    "                group_ids.extend(cdata['hierarchies'])\n",
    "            train_data.update(cdata['user_data'])\n",
    "\n",
    "    test_files = os.listdir(test_data_dir)\n",
    "    if test_data_dir is not None:\n",
    "        if 'test.json' in test_files:\n",
    "            with open(os.path.join(test_data_dir, 'test.json'), 'r') as f:\n",
    "                cdata = json.load(f)\n",
    "            test_data.update(cdata['user_data'])\n",
    "        else:\n",
    "            test_files = [f for f in test_files if f.endswith('.json')]\n",
    "            for f in test_files:\n",
    "                file_path = os.path.join(test_data_dir, f)\n",
    "                with open(file_path, 'r') as inf:\n",
    "                    cdata = json.load(inf)\n",
    "                test_data.update(cdata['user_data'])\n",
    "\n",
    "    client_ids = list(sorted(train_data.keys()))\n",
    "    return client_ids, group_ids, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3a2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "dataset_to_transform = {\n",
    "    'mnist': {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307), (0.3081))\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307), (0.3081))\n",
    "        ]),\n",
    "    },\n",
    "    'cifar10': {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    },\n",
    "    'cifar100': {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                 std=[0.267, 0.256, 0.276])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                 std=[0.267, 0.256, 0.276])\n",
    "        ]),\n",
    "    }\n",
    "}\n",
    "\n",
    "train_ds = datasets.MNIST('data/', train=True, download=True, transform=dataset_to_transform['mnist']['train'])\n",
    "test_ds = datasets.MNIST('data/', train=False, download=True, transform=dataset_to_transform['mnist']['val'])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "test_dl = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e5c919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting zip archive\n",
      "Downloading http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to data/EMNIST/raw/emnist.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c236db587d1646408ccba6896798d775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/EMNIST/raw/emnist.zip to data/EMNIST/raw\n",
      "Processing byclass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing bymerge\n",
      "Processing balanced\n",
      "Processing letters\n",
      "Processing digits\n",
      "Processing mnist\n",
      "Done!\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a581bce0c24d299e529bcb19bb5026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_emnist = datasets.EMNIST('data/', split='balanced', train=True, download=True, transform=dataset_to_transform['mnist']['train'])\n",
    "test_emnist = datasets.EMNIST('data/', split='balanced', train=False, download=True, transform=dataset_to_transform['mnist']['val'])\n",
    "train_cifar = datasets.CIFAR10('data/', train=True, download=True, transform=dataset_to_transform['cifar10']['train'])\n",
    "val_cifar = datasets.CIFAR10('data/', train=False, download=True, transform=dataset_to_transform['cifar10']['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdde7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_dir = '/workspace/leaf/FedProx/data/nist/data/train/'\n",
    "# test_data_dir = '/workspace/leaf/FedProx/data/nist/data/test/'\n",
    "# client_ids, group_ids, train_data, test_data = read_data(train_data_dir, test_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8d8437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def get_client_data(train_data, \n",
    "                    test_data=None,\n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    num_workers=0,\n",
    "                    **kwargs):\n",
    "    client_to_data = {}\n",
    "    for client_id in train_data.keys():\n",
    "        X_train = torch.Tensor(train_data[client_id]['x']).type(torch.float32)\n",
    "        # X_train = torch.Tensor(train_data[client_id]['x']).view.(-1, num_channels, img_size, img_size).type(torch.float32)\n",
    "        y_train = torch.Tensor(train_data[client_id]['y']).type(torch.int64)\n",
    "        train_dataset = [(x, y) for x, y in zip(X_train, y_train)]\n",
    "        client_to_data[client_id] = {}\n",
    "        client_to_data[client_id]['train'] = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            **kwargs\n",
    "        )\n",
    "        if test_data is not None:\n",
    "            X_test = torch.Tensor(test_data[client_id]['x']).type(torch.float32)\n",
    "            y_test = torch.Tensor(test_data[client_id]['y']).type(torch.int64)\n",
    "            test_dataset = [(x, y) for x, y in zip(X_test, y_test)]\n",
    "            client_to_data[client_id]['eval'] = DataLoader(\n",
    "                test_dataset, \n",
    "                batch_size=batch_size,\n",
    "                **kwargs\n",
    "            )\n",
    "        else:\n",
    "            client_to_data[client_id]['eval'] = None\n",
    "            \n",
    "    return client_to_data\n",
    "\n",
    "\n",
    "def get_clients(train_data,\n",
    "                test_data=None,\n",
    "                client_cls=None,\n",
    "                client_params=None,\n",
    "                dataloader_params=None):\n",
    "    client_cls = client_cls or Client\n",
    "    dataloader_params = dataloader_params or {}\n",
    "    client_params = client_params or {}\n",
    "#     if isinstance(client_params, dict):\n",
    "#         client_params = [client_params for _ in range(len(train_data))]\n",
    "    client_to_data = get_client_data(\n",
    "        train_data,\n",
    "        test_data, \n",
    "        **dataloader_params\n",
    "    )\n",
    "    clients = {}\n",
    "    for client_id in client_to_data.keys():\n",
    "        clients[client_id] = client_cls(client_id, \n",
    "                                     client_to_data[client_id]['train'],\n",
    "                                     eval_loader=client_to_data[client_id].get('eval'),\n",
    "                                     **client_params)\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae30f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sampling.py\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# def get_iid_shards(labels,\n",
    "#                    num_clients=100,\n",
    "#                    client_ids=None,\n",
    "#                    seed=None):\n",
    "#     \"\"\"Returns a homogeneous (IID) mapping of client ID's to sample indices of a dataset.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     labels : list, np.ndarray, torch.Tensor\n",
    "#         List of class labels for a dataset.\n",
    "#     num_clients : int (default=100)\n",
    "#         Number of clients used for training.\n",
    "#     client_ids : list, np.ndarray (default=None)\n",
    "#         List of client ID's. If `None`, defaults to a `range(num_clients)`.\n",
    "#     seed : int (default=None)\n",
    "#         Random state.\n",
    "       \n",
    "#     Notes\n",
    "#     -----\n",
    "#     ```\n",
    "#     num_samples_per_client = len(labels) // num_clients # 60000 / 100 = 600 for MNIST\n",
    "#     ```\n",
    "#     \"\"\"\n",
    "#     random_state = np.random.RandomState(seed)\n",
    "#     client_ids = client_ids or list(range(num_clients))\n",
    "    \n",
    "#     # randomly shuffle sample indices to generate IID (homogeneous) clients\n",
    "#     indices_shuffled = random_state.choice(range(len(labels)), len(labels), replace=False)\n",
    "#     num_samples_per_client = len(indices_shuffled) // num_clients\n",
    "\n",
    "#     # assign `num_samples_per_client` random samples to each client\n",
    "#     for i, client_id in enumerate(client_ids):\n",
    "#         client_indices = indices_shuffled[i * num_samples_per_client : (i + 1) * num_samples_per_client]\n",
    "#         client_to_shard[client_id] = client_indices\n",
    "    \n",
    "#     return client_to_shard\n",
    "    \n",
    "    \n",
    "# def get_client_shards(labels, \n",
    "#                       is_iid=True,\n",
    "#                       num_clients=100,\n",
    "#                       shard_size=300,\n",
    "#                       client_ids=None,\n",
    "#                       seed=None):\n",
    "#     \"\"\"Returns a mapping of client ID's to sample indices of a dataset.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     labels : list, np.ndarray, torch.Tensor\n",
    "#         List of class labels for a dataset.\n",
    "#     is_iid : bool\n",
    "#         Boolean whether to partition devices into homogenous (IID) or\n",
    "#         heterogeneous (non-IID) samples.\n",
    "#     num_clients : int (default=100)\n",
    "#         Number of clients used for training.\n",
    "#     client_ids : list, np.ndarray (default=None)\n",
    "#         List of client ID's. If `None`, defaults to a `range(num_clients)`.\n",
    "#     shard_size : int (default=300)\n",
    "#         Size of each shard to split labels by.\n",
    "#     seed : int (default=None)\n",
    "#         Random state.\n",
    "       \n",
    "#     Notes\n",
    "#     -----\n",
    "#     ```\n",
    "#     num_shards = len(labels) // shard_size # 60000 / 300 = 200 for MNIST\n",
    "#     num_shards_per_client = num_shards // num_clients # 200 / 100 = 2 for MNIST\n",
    "#     ```\n",
    "#     \"\"\"\n",
    "\n",
    "#     random_state = np.random.RandomState(seed)\n",
    "#     client_ids = client_ids or list(range(num_clients))\n",
    "#     client_to_shard = {c_id: [] for c_id in client_ids}\n",
    "#     if is_iid:\n",
    "#         # randomly shuffle sample indices if IID (homogoneous)\n",
    "#         sample_indices = random_state.choice(range(len(labels)), len(labels), replace=False)\n",
    "#     else:\n",
    "#         # sort sample indices by by label if non-IID (heterogeneous)\n",
    "#         sample_indices = np.argsort(labels).tolist()\n",
    "\n",
    "#     num_shards = len(labels) // shard_size\n",
    "#     num_shards_per_client = num_shards // num_clients # how many shards fit in each client\n",
    "#     shard_indices = set(range(num_shards))\n",
    "\n",
    "#     for i, client_id in enumerate(client_ids):\n",
    "#         client_shard_indices = random_state.choice(list(shard_indices), \n",
    "#                                                    num_shards_per_client, \n",
    "#                                                    replace=False)\n",
    "#         for shard_idx in client_shard_indices:\n",
    "#             client_to_shard[client_id].extend(\n",
    "#                 sample_indices[shard_idx*shard_size : (shard_idx+1)*shard_size]\n",
    "#             )\n",
    "#             shard_indices.remove(shard_idx)\n",
    "            \n",
    "#     return client_to_shard\n",
    "\n",
    "\n",
    "# def get_client_data(dataset, \n",
    "#                     num_clients,\n",
    "#                     client_ids=None,\n",
    "#                     is_iid=True,\n",
    "#                     shard_size=300,\n",
    "#                     batch_size=32,\n",
    "#                     shuffle=True,\n",
    "#                     seed=None,\n",
    "#                     dataloader_params=None):\n",
    "#     \"\"\"Returns a mapping of client ID's to their corresponding train & validation dataloaders.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     is_iid : bool (default=True)\n",
    "#         Boolean whether data is IID (Homogeneous) or non-IID (Heterogeneous)\n",
    "#     **kwargs\n",
    "#         Additional parameters used when instantiating each clients dataloader \n",
    "        \n",
    "#     \"\"\"\n",
    "#     dataloader_params = dataloader_params or {}\n",
    "#     client_to_data = {}\n",
    "#     labels = dataset.targets\n",
    "#     client_to_shard = get_client_shards(\n",
    "#         labels,\n",
    "#         is_iid=is_iid,\n",
    "#         num_clients=num_clients,\n",
    "#         client_ids=client_ids,\n",
    "#         shard_size=shard_size,\n",
    "#         seed=seed\n",
    "#     )\n",
    "#     # iterate through each client and create train/val dataloaders using the shard indices\n",
    "#     for k in client_to_shard.keys():\n",
    "#         client_indices = client_to_shard[k]\n",
    "#         client_dataset = SplitDataset(dataset, client_indices)\n",
    "#         # reseed workers for reproducibility\n",
    "# #         g = torch.Generator()\n",
    "# #         g.manual_seed(0)\n",
    "#         client_to_data[k] = DataLoader(\n",
    "#             client_dataset, \n",
    "#             batch_size=batch_size,\n",
    "#             shuffle=shuffle, \n",
    "# #             worker_init_fn=seed_worker,\n",
    "# #             generator=g,\n",
    "#             **dataloader_params\n",
    "#         )\n",
    "        \n",
    "#     return client_to_data\n",
    "\n",
    "\n",
    "# def get_clients(dataset,\n",
    "#                 num_clients=100,\n",
    "#                 client_cls=None,\n",
    "#                 client_ids=None,\n",
    "#                 is_iid=True,\n",
    "#                 shard_size=300,\n",
    "#                 batch_size=32,\n",
    "#                 client_params=None,\n",
    "#                 dataloader_params=None):\n",
    "#     client_cls = client_cls or Client\n",
    "#     client_params = client_params or {}\n",
    "# #     if client_params is None:\n",
    "# #         client_params = {}\n",
    "# #     elif isinstance(client_params, dict):\n",
    "# #         client_params = [client_params for _ in range(num_clients)]\n",
    "#     client_to_data = get_client_data(\n",
    "#         dataset,\n",
    "#         num_clients=num_clients,\n",
    "#         client_ids=client_ids,\n",
    "#         is_iid=is_iid,\n",
    "#         shard_size=shard_size,\n",
    "#         batch_size=batch_size,\n",
    "#         dataloader_params=dataloader_params\n",
    "#     )\n",
    "#     clients = {\n",
    "#         k: client_cls(k, dl, **client_params)\n",
    "#         for k, dl\n",
    "#         in client_to_data.items()\n",
    "#     }\n",
    "#     return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "663d30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.py\n",
    "\n",
    "\n",
    "class Client:\n",
    "    \"\"\"Base client.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    client_id : str\n",
    "        Id of the client.\n",
    "    dataloader : DataLoader\n",
    "        Local dataset used for training on the client.\n",
    "    \"\"\"\n",
    "    def __init__(self, client_id, train_loader, eval_loader=None, device='cpu'):\n",
    "        self.client_id = client_id\n",
    "        self.train_loader = train_loader\n",
    "        self.eval_loader = eval_loader\n",
    "        self.device = device\n",
    "        self._model = None\n",
    "        self._device = None\n",
    "        self._optimizer = None\n",
    "        self._scheduler = None\n",
    "        \n",
    "        self._local_steps = 0\n",
    "        \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self._model = model\n",
    "\n",
    "    @property\n",
    "    def optimizer(self):\n",
    "        return self._optimizer\n",
    "    \n",
    "    @optimizer.setter\n",
    "    def optimizer(self, optimizer):\n",
    "        self._optimizer = optimizer\n",
    "    \n",
    "    @property\n",
    "    def scheduler(self):\n",
    "        return self._scheduler\n",
    "    \n",
    "    @scheduler.setter\n",
    "    def scheduler(self, scheduler):\n",
    "        self._scheduler = scheduler\n",
    "    \n",
    "    @property\n",
    "    def local_steps(self):\n",
    "        return self._local_steps\n",
    "    \n",
    "    @local_steps.setter\n",
    "    def local_steps(self, v):\n",
    "        self._local_steps = v\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train_loader.dataset)\n",
    "    \n",
    "    def _update(self, criterion, num_epochs=1):\n",
    "        \"\"\"Algorithm 1 (ClientUpdate).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_epochs (E) : int\n",
    "            Number of epochs.\n",
    "        criterion : \n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.model.to(self.device)\n",
    "        self.local_steps = 0\n",
    "        \n",
    "        total_loss = np.zeros(num_epochs, dtype=np.float32)\n",
    "        total_correct = np.zeros(num_epochs, dtype=np.float32)\n",
    "        for i in range(num_epochs):\n",
    "            for x, y in self.train_loader:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                logits = self.model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss[i] += loss.item()\n",
    "                total_correct[i] += (logits.argmax(-1) == y).sum().item()\n",
    "                self.local_steps += 1\n",
    "                \n",
    "            # set this to a function we can call that way inherritance is easier\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step()\n",
    "        \n",
    "        metrics = {\n",
    "            'loss': total_loss / len(self.train_loader),\n",
    "            'accuracy': total_correct / len(self)\n",
    "        }\n",
    "#         if self.eval_loader is not None:\n",
    "#             val_metrics = self.validate(criterion)\n",
    "#             for k, v in val_metrics:\n",
    "#                 metrics[f'val_{k}'] = v\n",
    "                \n",
    "        # move model back to cpu\n",
    "        self.model.to('cpu')\n",
    "        return metrics\n",
    "    \n",
    "    def update(self, criterion, num_epochs=1):\n",
    "        return self._update(criterion, num_epochs)\n",
    "\n",
    "    def validate(self, criterion):\n",
    "        self.model.eval()\n",
    "        loss = 0 \n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.eval_loader:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                logits = self.model(x)\n",
    "                correct += (logits.argmax(-1) == y).sum().item()\n",
    "                loss += criterion(logits, y).item()\n",
    "                \n",
    "        metrics = {\n",
    "            'loss': loss / len(self.eval_loader),\n",
    "            'accuracy': correct / len(self.eval_loader.dataset)\n",
    "        }\n",
    "        return metrics\n",
    "    \n",
    "    def get_gradients(self, criterion):\n",
    "        return get_gradients(self.model, self.train_loader, criterion, device=self.device)\n",
    "    \n",
    "    \n",
    "class SCAFFOLDClient:\n",
    "    \n",
    "    def __init__(self, client_id, train_loader, eval_loader=None, option='II', device='cpu'):\n",
    "        super().__init__(client_id, train_loader, eval_loader, eval_loader, device)\n",
    "        self.option = option\n",
    "        self.control = None\n",
    "        self.control_new = None\n",
    "        self.control_delta = None\n",
    "        self._control_server = None\n",
    "        \n",
    "    @property\n",
    "    def control_server(self):\n",
    "        return self._control_server\n",
    "    \n",
    "    @control_server.setter\n",
    "    def control_server(self, control_server):\n",
    "        self._control_server = control_server\n",
    "        \n",
    "    def set_control_variates(self):\n",
    "        # set control variates if first update\n",
    "        if self.control is None:\n",
    "            self.control = [torch.zeros_like(p.data) for p in self.model]\n",
    "        if self.control_new is None:\n",
    "            self.control_new = [torch.zeros_like(p.data) for p in self.model]\n",
    "        if self.contrl_delta is None:\n",
    "            self.control_delta = [torch.zeros_like(p.data) for p in self.model]\n",
    "            \n",
    "    def update(self, criterion, num_epochs=1):\n",
    "        self.set_control_variates()\n",
    "        model_server = deepcopy(self.model)\n",
    "        results = self._update(criterion, num_epochs=num_epochs)\n",
    "        \n",
    "        # (4) updates to the local control variate\n",
    "        if self.option == 'I':\n",
    "            # gradients of global model w.r.t local data\n",
    "            grads = get_gradients(model_server, self.dataset, criterion, device=self.device)\n",
    "            for d_p, ci_new in zip(grads, self.control_new):\n",
    "                ci_new.data = d_p.data\n",
    "        elif self.option == 'II':\n",
    "            grads = [torch.zeros_like(p.data) for p in self.model.parameters()]\n",
    "            for p_server, p_client, d_p in zip(model_server.parameters(), zip(self.model.parameters()), grads):\n",
    "                d_p.data = p_client.data.detach() - p_server.data.detach()\n",
    "                \n",
    "            lr = self.optimizer.param_groups[0]['lr']\n",
    "            for ci, ci_new, c, d_p in zip(self.control, self.control_new, control_server, grads):\n",
    "                ci_new.data = ci - c + 1 / (self.local_steps * lr) * d_p.data\n",
    "#                 ci_delta.data = - c + 1 / (self.local_steps * lr) * d_p.data\n",
    "        \n",
    "        # store the control correction used in (5) and update the local control variate\n",
    "        for ci, ci_new, ci_delta in zip(self.control, self.control_new, self.control_delta):\n",
    "            ci_delta.data = ci_new.data - ci.data\n",
    "            ci.data = ci_new.data\n",
    "            \n",
    "        return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "181843f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(model, dataset, criterion, device='cpu'):\n",
    "    \"\"\"Returns a list of gradients of `model` w.r.t. `dataset`\"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    # clear gradients\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None and p.requires_grad:\n",
    "            p.grad.zero_()\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        # accumulate the average gradient of each batch\n",
    "        loss.backward()\n",
    "\n",
    "    # normalize the accumulated gradient across batches\n",
    "    grads = []\n",
    "    for p in model.parameters():\n",
    "        # what to do when the model has layers that don't require gradients?\n",
    "        grads.append(p.grad / len(dataloader))\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f2a5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class SplitDataset(Dataset):\n",
    "    \"\"\"Dataset for a client partitioned by a list of indices.\"\"\"\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = list(indices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[self.indices[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c7ce54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"CNN described in \"Communication-Efficient Learning of Deep Networks\n",
    "    from Decentralized Data\" (https://arxiv.org/pdf/1602.05629.pdf).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_features : int (default=1)\n",
    "        Number of channels in the input image.\n",
    "    num_classes : int (default=10)\n",
    "        Number of class labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self._in_features = in_features\n",
    "        self._num_classes = num_classes\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(self._in_features, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, self._num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    \"\"\"CNN described in \"Communication-Efficient Learning of Deep Networks\n",
    "    from Decentralized Data\" (https://arxiv.org/pdf/1602.05629.pdf).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_features : int (default=784)\n",
    "        Number input features.\n",
    "    hidden_dim : int (cdefault=200)\n",
    "        Number of hidden units.\n",
    "    num_classes : int (default=10)\n",
    "        Number of class labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features=784, hidden_dim=200, num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self._in_features = in_features\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self._num_classes = num_classes\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._in_features, self._hidden_dim)\n",
    "        self.fc2 = nn.Linear(self._hidden_dim, self._num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \"\"\"Multinomial Logistic Regression\"\"\"\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self._in_features = in_features\n",
    "        self._num_classes = num_classes\n",
    "        self.fc = nn.Linear(self._in_features, self._num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "MODEL_MAP = {\n",
    "    'cnn': CNN,\n",
    "    'mlp': MLP,\n",
    "    'lr': LogisticRegression\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "073f00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# servers (aggregates parameters from local solvers)\n",
    "    # base.py\n",
    "    # fedavg.py\n",
    "    # fedprox.py\n",
    "    # feddane.py\n",
    "    # fednova.py\n",
    "    # fedopt.py\n",
    "    # scaffold.py\n",
    "# optimizers (local solvers)\n",
    "    # fedprox.py\n",
    "    # feddane.py\n",
    "    # fedopt.py\n",
    "    # scaffold.py\n",
    "    # fednova.py\n",
    "# utils\n",
    "    # client.py\n",
    "    # sampling.py\n",
    "# models\n",
    "    # mnist\n",
    "        # cnn.py\n",
    "        # mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8d700a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a server for each algo\n",
    "# create a client for each algo\n",
    "# create an optimizer for each algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf21843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers/fedprox.py\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "\n",
    "class FedProxSolver(Optimizer):\n",
    "    \"\"\"Implements FedProx local solver.\n",
    "    \n",
    "    This adds a proximal term to any clients optimizer.\n",
    "    \n",
    "    This wrapper allows us to pass in any torch.optim.Optimizer for\n",
    "    a given client, not limited to SGD as originally proposed.\n",
    "    \n",
    "    Args:\n",
    "        optimizer (torch.optim.Optimizer): local optimizer.\n",
    "        mu (float): proximal term weight (default: 0)\n",
    "\n",
    "    __ https://arxiv.org/pdf/1812.06127.pdf\n",
    "        \n",
    "    Example:\n",
    "        >>> # train a model locally for a client\n",
    "        >>> client_optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "        >>> client_optimizer = FedProxLocal(client_optimizer, mu=0.1)\n",
    "        >>> client_optimizer.zero_grad()\n",
    "        >>> loss_fn(model(input), target).backward()\n",
    "        >>> client_optimizer.step()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 optimizer,\n",
    "                 mu=0):\n",
    "        if mu < 0.0:\n",
    "            raise ValueError(f'Invalid mu value: {mu}')\n",
    "        self.optimizer = optimizer\n",
    "        self.mu = mu\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = self.optimizer.state\n",
    "    \n",
    "    def _update(self, group):\n",
    "        \"\"\"Applies a proximal update to a parameter group.\"\"\"\n",
    "        for p in group['params']:\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            state = self.state[p]\n",
    "            p.data.add_(state['proximal'], alpha=-group['lr'])\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        closure : bool\n",
    "            A closure that reevaluates the model and returns the loss.\n",
    "        \"\"\"\n",
    "        # set the initial (global) weights and proximal term before we update the client optimizer\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                state = self.state[p]\n",
    "                if 'initial_weights' not in state:\n",
    "                    state['initial_weights'] = torch.clone(p.data).detach()\n",
    "                state['proximal'] = self.mu * (p.data - state['initial_weights'])\n",
    "\n",
    "        loss = self.optimizer.step(closure=closure)\n",
    "        for group in self.param_groups:\n",
    "            self._update(group)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class FedDaneSolver(Optimizer):\n",
    "    \"\"\"Implements FedDane local solver.\n",
    "    \n",
    "    Args:\n",
    "        optimizer (torch.optim.Optimizer): local optimizer.\n",
    "        mu (float): proximal term weight (default: 0)\n",
    "    \n",
    "        \n",
    "    Example:\n",
    "        >>> # train a model locally for a client\n",
    "        >>> client_optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "        >>> client_optimizer = FedDaneLocal(client_optimizer, average_gradients, mu=0.1)\n",
    "        >>> client_optimizer.zero_grad()\n",
    "        >>> loss_fn(model(input), target).backward()\n",
    "        >>> client_optimizer.step()\n",
    "    \n",
    "    __ https://arxiv.org/pdf/2001.01920.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 optimizer,\n",
    "                 average_gradients,\n",
    "                 mu=0):\n",
    "        if mu < 0.0:\n",
    "            raise ValueError(f'Invalid mu value: {mu}')\n",
    "        self.optimizer = optimizer\n",
    "        self.average_gradients = average_gradients\n",
    "        self.mu = mu\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = self.optimizer.state\n",
    "    \n",
    "    def _update(self, group):\n",
    "        \"\"\"Applies a proximal update to a parameter group.\"\"\"\n",
    "        for p in group['params']:\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            state = self.state[p]\n",
    "            p.data.add_(state['proximal'] + state['grad_delta'], alpha=-group['lr'])\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        closure : bool\n",
    "            A closure that reevaluates the model and returns the loss.\n",
    "        \"\"\"\n",
    "        # set the initial (global) weights and proximal term before we update the client optimizer\n",
    "        for group in self.param_groups:\n",
    "            for i, p in enumerate(group['params']):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                state = self.state[p]\n",
    "                if 'initial_weights' not in state:\n",
    "                    state['initial_weights'] = torch.clone(p.data).detach()\n",
    "                state['proximal'] = self.mu * (p.data - state['initial_weights'])\n",
    "                if 'average_gradient' not in state:\n",
    "                    state['average_gradient'] = torch.clone(self.average_gradients[i]).detach()\n",
    "                state['grad_delta'] = state['average_gradient'] - p.grad.data\n",
    "\n",
    "        loss = self.optimizer.step(closure=closure)\n",
    "        for group in self.param_groups:\n",
    "            self._update(group)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class FedNovaSolver(Optimizer):\n",
    "    \"\"\"Implements FedNova local solver.\n",
    "    \n",
    "    Args:\n",
    "        optimizer (torch.optim.Optimizer): local optimizer.\n",
    "        mu (float): proximal term weight (default: 0)\n",
    "\n",
    "    __ https://arxiv.org/pdf/2007.07481.pdf\n",
    "        \n",
    "    Example:\n",
    "        >>> # train a model locally for a client\n",
    "        >>> client_optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "        >>> client_optimizer = FedNovaLocal(client_optimizer, mu=0.1)\n",
    "        >>> client_optimizer.zero_grad()\n",
    "        >>> loss_fn(model(input), target).backward()\n",
    "        >>> client_optimizer.step()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 optimizer,\n",
    "                 mu=0):\n",
    "        if mu < 0.0:\n",
    "            raise ValueError(f'Invalid mu value: {mu}')\n",
    "        self.optimizer = optimizer\n",
    "        self.mu = mu\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = self.optimizer.state\n",
    "    \n",
    "    def _update(self, group):\n",
    "        \"\"\"Applies a proximal update to a parameter group.\"\"\"\n",
    "        for p in group['params']:\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            state = self.state[p]\n",
    "            p.data.add_(state['proximal'], alpha=-group['lr'])\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        closure : bool\n",
    "            A closure that reevaluates the model and returns the loss.\n",
    "        \"\"\"\n",
    "        # set the initial (global) weights and proximal term before we update the client optimizer\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                state = self.state[p]\n",
    "                if 'initial_weights' not in state:\n",
    "                    state['initial_weights'] = torch.clone(p.data).detach()\n",
    "                state['proximal'] = self.mu * (p.data - state['initial_weights'])\n",
    "\n",
    "        # update the weights and gradient with the client optimizer\n",
    "        loss = self.optimizer.step(closure=closure)\n",
    "        \n",
    "        # update the weights by adding the (negative) proximal term\n",
    "        for group in self.param_groups:\n",
    "            self._update(group)\n",
    "        \n",
    "        # accumualte gradients after calculating loss\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                momentum = group.get('momentum', 0)\n",
    "                \n",
    "                state = self.state[p]\n",
    "                if 'local_step' not in state:\n",
    "                    state['local_step'] = 0\n",
    "                state['local_step'] += 1\n",
    "                \n",
    "                # momentum (1 - p^t) / (1 - p)\n",
    "                a = (1 - momentum ** state['local_step']) / (1 - momentum)\n",
    "                # proximal (1 - lr * mu)^t\n",
    "                a *= (1 - group['lr'] * self.mu) ** (state['local_step']-1)\n",
    "                # record the norm factor (a) to divide the l1-norm during aggregation\n",
    "                if 'norm_factor' not in state:\n",
    "                    state['norm_factor'] = []\n",
    "                state['norm_factor'].append(a)\n",
    "                \n",
    "                if 'cgrad' not in state:\n",
    "                    state['cgrad'] = torch.clone(p.grad.data).detach()\n",
    "                    state['cgrad'].mul_(group['lr']) # do we need the lr ?\n",
    "                    state['cgrad'].mul_(a) # G * a\n",
    "                else:\n",
    "                    state['cgrad'].add_(p.grad.data, alpha=group['lr'])\n",
    "                    state['cgrad'].mul_(a) # G * a\n",
    "                    \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class SCAFFOLDSolver(Optimizer):\n",
    "    \"\"\"Implements SCAFFOLD local solver.\n",
    "    \n",
    "    Args:\n",
    "        optimizer (torch.optim.Optimizer): local optimizer.\n",
    "\n",
    "    __ https://arxiv.org/pdf/1910.06378.pdf\n",
    "        \n",
    "    Example:\n",
    "        >>> # train a model locally for a client\n",
    "        >>> client_optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "        >>> client_optimizer = SCAFFOLDSolver(client_optimizer, mu=0.1)\n",
    "        >>> client_optimizer.zero_grad()\n",
    "        >>> loss_fn(model(input), target).backward()\n",
    "        >>> client_optimizer.step()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimizer, control_global, control_local):\n",
    "        if isinstance(control_global, torch.Tensor):\n",
    "            raise TypeError(\"control_global argument given to the optimizer should be \"\n",
    "                            \"an iterable of Tensors or lists, but got \" +\n",
    "                            torch.typename(control_global))\n",
    "        if isinstance(control_global[0], torch.Tensor):\n",
    "            control_global = [control_global]\n",
    "        if isinstance(control_local, torch.Tensor):\n",
    "            raise TypeError(\"control_local argument given to the optimizer should be \"\n",
    "                            \"an iterable of Tensors or lists, but got \" +\n",
    "                            torch.typename(control_local))\n",
    "        if isinstance(control_local[0], torch.Tensor):\n",
    "            control_local = [control_local]\n",
    "            \n",
    "        self.optimizer = optimizer\n",
    "        self.control_global = control_global\n",
    "        self.control_local = control_local\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = self.optimizer.state\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        closure : bool\n",
    "            A closure that reevaluates the model and returns the loss.\n",
    "        \"\"\"\n",
    "        # update the weights and gradient with the client optimizer\n",
    "        loss = self.optimizer.step(closure=closure)\n",
    "        \n",
    "        # (3) update the weights by adding the control variate correction term\n",
    "        for group, group_global, group_local in zip(self.param_groups, self.control_global, self.control_local):\n",
    "            for p, c, ci in zip(group, group_global, group_local):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p.data.add_(c - ci, -group['lr'])\n",
    "                    \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "044a2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# servers/base.py\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "\n",
    "class BaseFederater:\n",
    "    \"\"\"Base Federater.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "    dataset : torch.utils.data.Dataset\n",
    "    num_clients (K) : int (default=100)\n",
    "        Number of clients to partition `dataset`.\n",
    "    batch_size (B) : int, dict[str, int] (defualt=32)\n",
    "        Number of samples per batch to load on each client. \n",
    "        Can be a dictionary mapping each client ID to it's corresponding batch size\n",
    "        to allow for various batch sizes across clients.\n",
    "    shard_size : int (default=300)\n",
    "    is_iid : bool (default=False)\n",
    "    drop_last : bool (default=True)\n",
    "    num_workers : int (default=0)\n",
    "    device : str (default='cpu')\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 clients,\n",
    "                 client_optimizer_cls,\n",
    "                 client_optimizer_params,\n",
    "                 server_optimizer=None,\n",
    "                 client_scheduler_cls=None,\n",
    "                 client_scheduler_params=None,\n",
    "                 server_scheduler=None,\n",
    "                 seed=None,\n",
    "                 writer=None):\n",
    "        self.model = model\n",
    "        self.clients = clients\n",
    "        self.client_optimizer_cls = client_optimizer_cls\n",
    "        self.client_optimizer_params = client_optimizer_params\n",
    "        self.server_optimizer = server_optimizer\n",
    "        self.client_scheduler_cls = client_scheduler_cls\n",
    "        self.client_scheduler_params = client_scheduler_params\n",
    "        self.server_scheduler = server_scheduler\n",
    "        self.writer = writer or SummaryWriter()\n",
    "        \n",
    "        self.client_ids = list(self.clients.keys())\n",
    "        self.num_clients = len(self.clients)\n",
    "        self.num_samples = sum([len(c) for c in self.clients.values()]) # n\n",
    "        self.client_weights = [len(c) / self.num_samples for c in self.clients.values()]\n",
    "        \n",
    "        self.device = next(self.model.parameters()).device\n",
    "        self._global_round = 0\n",
    "        self._random_state = np.random.RandomState(seed)\n",
    "        \n",
    "    @property\n",
    "    def global_round(self):\n",
    "        return self._global_round\n",
    "\n",
    "    @global_round.setter\n",
    "    def global_round(self, global_round):\n",
    "        self._global_round = global_round\n",
    "    \n",
    "    def aggregate(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def update(self, \n",
    "               client_ids, \n",
    "               criterion,\n",
    "               num_epochs, \n",
    "               straggler_rate=0):\n",
    "        \"\"\"Performs a full communication round.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        client_ids (S_t): list, np.ndarray\n",
    "            List of client ID's to train.\n",
    "        criterion : nn.Module\n",
    "            Loss function to optimize on each client.\n",
    "        num_epochs (E): int\n",
    "            Number of epochs to train on each client.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        metrics_dict : dict\n",
    "            Dictionary mapping each metric to the average score across `client_ids`\n",
    "        \"\"\"\n",
    "        # send the global model parameters to each client\n",
    "        self.send_model()\n",
    "        \n",
    "        metrics_dict = defaultdict(lambda: 0)\n",
    "        for k in client_ids:\n",
    "            start_time = time.time()\n",
    "            # instantiate client optimizer and scheduler\n",
    "            client = self.clients[k]\n",
    "            client.optimizer = self.get_client_optimizer(client)\n",
    "            client.scheduler = self.get_client_scheduler(client.optimizer)\n",
    "            \n",
    "            # for heterogeneity experiments we can train clients for varying epochs (stragglers)\n",
    "            if self._random_state.random() < straggler_rate:\n",
    "                client_epochs = self._random_state.choice(range(1, num_epochs+1))\n",
    "            else:\n",
    "                client_epochs = num_epochs\n",
    "                \n",
    "            # update the client weights and record the local training metrics\n",
    "            client_metrics_dict = client.update(\n",
    "                criterion,\n",
    "                num_epochs=client_epochs,\n",
    "            )\n",
    "            \n",
    "            # update the summary writer and record loss/acc from the client\n",
    "            elapsed_time = time.time() - start_time\n",
    "            self.writer.add_scalar(f'clients/{k}/elapsed_time', elapsed_time, self.global_round)\n",
    "            for metric, values in client_metrics_dict.items():\n",
    "                for i, value in enumerate(values):\n",
    "                    self.writer.add_scalar(f'client/{k}/round_{self.global_round}/{metric}', \n",
    "                                           value,\n",
    "                                           self.global_round)\n",
    "                metrics_dict[metric] += values[-1] / len(client_ids)\n",
    "        \n",
    "        # aggregate the parameters of the local solvers\n",
    "        self.aggregate()\n",
    "        if self.server_scheduler is not None:\n",
    "            self.server_scheduler.step()\n",
    "        \n",
    "        return metrics_dict\n",
    "        \n",
    "    def fit(self, \n",
    "            num_rounds,\n",
    "            criterion, \n",
    "            num_epochs,\n",
    "            val_dl=None,\n",
    "            C=0.1,\n",
    "            straggler_rate=0,\n",
    "            eval_every_n=1):\n",
    "        \"\"\"Train loop.\"\"\"\n",
    "        start_time = time.time()\n",
    "        # subset a sample of `m` clients each round\n",
    "        m = max(int(np.ceil(self.num_clients * C)), 1)\n",
    "        for t in range(num_rounds):\n",
    "            self.global_round += 1\n",
    "            \n",
    "            # update a subset of clients with the local solver\n",
    "            S = self._random_state.choice(self.client_ids, m, replace=False)\n",
    "            train_metrics = self.update(client_ids=S, \n",
    "                                        criterion=criterion,\n",
    "                                        num_epochs=num_epochs, \n",
    "                                        straggler_rate=straggler_rate)\n",
    "            \n",
    "            # log train summary metrics\n",
    "            elapsed_time = round(time.time() - start_time)\n",
    "            self.writer.add_scalar('train/elapsed_time', elapsed_time, self.global_round)\n",
    "            template_str = f'round {self.global_round} - {elapsed_time}s'\n",
    "            for metric, value in train_metrics.items():\n",
    "                self.writer.add_scalar(f'train/{metric}', value, self.global_round)\n",
    "                template_str += f' - train_{metric} : {value:0.4f}'\n",
    "                \n",
    "            # log validation summary metrics\n",
    "            if eval_every_n is not None and t % eval_every_n == 0:\n",
    "                val_metrics = self.validate(criterion)\n",
    "                for metric, value in val_metrics.items():\n",
    "                    self.writer.add_scalar(f'val/{metric}', value, self.global_round)\n",
    "                    template_str += f' - val_{metric} : {value:0.4f}'\n",
    "                \n",
    "            print(template_str)\n",
    "    \n",
    "    def get_client_optimizer(self, client):\n",
    "        \"\"\"Returns a client optimizer (local solver).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : iterable\n",
    "            Client parameters to optimize\n",
    "        optimizer_params : dict\n",
    "            Client optimizer hyperparameters\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.optim.Optimizer\n",
    "        \"\"\"\n",
    "        optimizer_params = self.client_optimizer_params or {}\n",
    "        return self.client_optimizer_cls(client.model.parameters(), **optimizer_params)\n",
    "    \n",
    "    def get_client_scheduler(self, optimizer):\n",
    "        \"\"\"Returns a LR scheduler for a client optimizer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        optimizer : torch.optim.Optimizer\n",
    "            Client optimizer\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.optim.lr_scheduler._LRScheduler or None\n",
    "            Client LR scheduler, or None if not specified\n",
    "        \"\"\"\n",
    "        if self.client_scheduler_cls is not None:\n",
    "            scheduler_params = self.client_scheduler_params or {}\n",
    "            return self.client_scheduler_cls(optimizer, **scheduler_params)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def validate(self, criterion, client_ids=None):\n",
    "        eval_metrics = defaultdict(lambda: 0)\n",
    "        \n",
    "        # send server model to each client for validation\n",
    "        client_ids = client_ids or self.client_ids\n",
    "        self.send_model(client_ids)\n",
    "        \n",
    "        # validate on each client\n",
    "        for client_id in client_ids:\n",
    "            client = self.clients[client_id]\n",
    "            client_metrics = client.validate(criterion=criterion)\n",
    "            for metric, value in client_metrics.items():\n",
    "                eval_metrics[metric] += value / len(client_ids)\n",
    "        return eval_metrics\n",
    "    \n",
    "#     def validate(self, val_dl, criterion):\n",
    "# #         self.model.to(self.device)\n",
    "#         self.model.eval()\n",
    "#         loss = 0 \n",
    "#         correct = 0\n",
    "#         with torch.no_grad():\n",
    "#             for x, y in val_dl:\n",
    "#                 x = x.to(self.device)\n",
    "#                 y = y.to(self.device)\n",
    "#                 logits = self.model(x)\n",
    "#                 correct += (logits.argmax(-1) == y).sum().item()\n",
    "#                 loss += criterion(logits, y).item()\n",
    "                \n",
    "#         results = {\n",
    "#             'loss': loss / len(val_dl),\n",
    "#             'accuracy': correct / len(val_dl.dataset)\n",
    "#         }\n",
    "#         return results\n",
    "    \n",
    "    def send_model(self, client_ids=None):\n",
    "        \"\"\"Send the current state of the global model to each client.\"\"\"\n",
    "        if client_ids is None:\n",
    "            client_ids = self.client_ids\n",
    "        for client_id in client_ids:\n",
    "            self.clients[client_id].model = deepcopy(self.model)\n",
    "            \n",
    "    def get_gradients(self, client_ids, criterion):\n",
    "        self.send_model(client_ids)\n",
    "        grads = []\n",
    "        for k, client_id in enumerate(client_ids):\n",
    "            client = self.clients[client_id]\n",
    "            client_grads = client.get_gradients(criterion)\n",
    "            grads.append(client_grads)\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d847fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvg(BaseFederater):\n",
    "    \"\"\"Federated Averaging (FedAvg)\n",
    "    \n",
    "    https://arxiv.org/pdf/1602.05629.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 clients,\n",
    "                 client_optimizer_cls,\n",
    "                 client_optimizer_params,\n",
    "                 client_scheduler_cls=None,\n",
    "                 client_scheduler_params=None,\n",
    "                 seed=None,\n",
    "                 writer=None):\n",
    "        super().__init__(model,\n",
    "                         clients,\n",
    "                         client_optimizer_cls=client_optimizer_cls,\n",
    "                         client_optimizer_params=client_optimizer_params,\n",
    "                         client_scheduler_cls=client_scheduler_cls,\n",
    "                         client_scheduler_params=client_scheduler_params,\n",
    "                         seed=seed,\n",
    "                         writer=writer)\n",
    "    \n",
    "    def aggregate(self):\n",
    "        global_state = {} # self.model.state_dict()\n",
    "        for k, (client_id, client) in enumerate(self.clients.items()):\n",
    "            local_state = client.model.state_dict()\n",
    "            for layer_name, param in local_state.items():\n",
    "                if k == 0:\n",
    "                    global_state[layer_name] = self.client_weights[k] * param\n",
    "                else:\n",
    "                    global_state[layer_name] += self.client_weights[k] * param\n",
    "\n",
    "        self.model.load_state_dict(global_state)\n",
    "                    \n",
    "\n",
    "class FedProx(BaseFederater):\n",
    "    \"\"\"FedProx\n",
    "    \n",
    "    https://arxiv.org/pdf/1812.06127.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 clients,\n",
    "                 client_optimizer_cls,\n",
    "                 client_optimizer_params,\n",
    "                 server_optimizer,\n",
    "                 mu=0,\n",
    "                 client_scheduler_cls=None,\n",
    "                 client_scheduler_params=None,\n",
    "                 server_scheduler=None,\n",
    "                 seed=None,\n",
    "                 writer=None):\n",
    "        super().__init__(model,\n",
    "                         clients,\n",
    "                         client_optimizer_cls,\n",
    "                         client_optimizer_params,\n",
    "                         server_optimizer=server_optimizer,\n",
    "                         server_scheduler=server_scheduler,\n",
    "                         client_scheduler_cls=client_scheduler_cls,\n",
    "                         client_scheduler_params=client_scheduler_params,\n",
    "                         seed=seed,\n",
    "                         writer=writer)\n",
    "        self.mu = mu\n",
    "            \n",
    "    def get_client_optimizer(self, client):\n",
    "        optimizer_params = self.client_optimizer_params or {}\n",
    "        client_optimizer = self.client_optimizer_cls(client.model.parameters(), **optimizer_params)\n",
    "        return FedProxSolver(client_optimizer, mu=self.mu)\n",
    "    \n",
    "    def aggregate(self):\n",
    "        self.server_optimizer.zero_grad()\n",
    "        for k, client in enumerate(self.clients.values()):\n",
    "            for p_server, p_client in zip(self.model.parameters(), client.model.parameters()):\n",
    "                if p_server.requires_grad:\n",
    "                    if k == 0:\n",
    "                        p_server.grad = self.client_weights[k] * (p_server.data - p_client.data)\n",
    "                    else:\n",
    "                        p_server.grad.data.add_(p_server.data - p_client.data, alpha=self.client_weights[k])\n",
    "        \n",
    "        self.server_optimizer.step()\n",
    "\n",
    "    \n",
    "class FedOpt(BaseFederater):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 clients,\n",
    "                 client_optimizer_cls,\n",
    "                 client_optimizer_params,\n",
    "                 server_optimizer,\n",
    "                 server_scheduler=None,\n",
    "                 client_scheduler_cls=None,\n",
    "                 client_scheduler_params=None,\n",
    "                 seed=None,\n",
    "                 writer=None):\n",
    "        super().__init__(model,\n",
    "                         clients,\n",
    "                         client_optimizer_cls,\n",
    "                         client_optimizer_params,\n",
    "                         server_optimizer=server_optimizer,\n",
    "                         server_scheduler=server_scheduler,\n",
    "                         client_scheduler_cls=client_scheduler_cls,\n",
    "                         client_scheduler_params=client_scheduler_params,\n",
    "                         seed=seed,\n",
    "                         writer=writer)\n",
    "    \n",
    "    def aggregate(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.server_optimizer.zero_grad()\n",
    "        # iterate through each client\n",
    "        for k, client in enumerate(self.clients.values()):\n",
    "            for p_server, p_client in zip(self.model.parameters(), client.model.parameters()):\n",
    "                if p_server.requires_grad:\n",
    "                    if k == 0:\n",
    "                        p_server.grad = client_weights[k] * (p_server.data - p_client.data)\n",
    "                    else:\n",
    "                        p_server.grad.add_(p_server.data - p_client.data, alpha=self.client_weights[k])\n",
    "        \n",
    "        self.server_optimizer.step()\n",
    "        \n",
    "        \n",
    "class FedNova(BaseFederater):\n",
    "    \"\"\"FedNova\n",
    "    \n",
    "    https://arxiv.org/pdf/2007.07481.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 clients,\n",
    "                 server_optimizer,\n",
    "                 client_optimizer_cls,\n",
    "                 client_optimizer_params,\n",
    "                 mu=0,\n",
    "                 server_scheduler=None,\n",
    "                 client_scheduler_cls=None,\n",
    "                 client_scheduler_params=None,\n",
    "                 seed=None,\n",
    "                 writer=None):\n",
    "        super().__init__(model,\n",
    "                         clients,\n",
    "                         client_optimizer_cls=client_optimizer_cls,\n",
    "                         client_optimizer_params=client_optimizer_params,\n",
    "                         server_optimizer=server_optimizer,\n",
    "                         server_scheduler=server_scheduler,\n",
    "                         client_scheduler_cls=client_scheduler_cls,\n",
    "                         client_scheduler_params=client_scheduler_params,\n",
    "                         seed=seed,\n",
    "                         writer=writer)\n",
    "        self.mu = mu\n",
    "        \n",
    "    def get_client_optimizer(self, client):\n",
    "        optimizer_params = self.client_optimizer_params or {}\n",
    "        client_optimizer = self.client_optimizer_cls(client.model.parameters(), **optimizer_params)\n",
    "        client_optimizer = FedNovaSolver(client_optimizer, mu=self.mu)\n",
    "        return client_optimizer\n",
    "    \n",
    "    def aggregate(self):\n",
    "        \"\"\" \"\"\"\n",
    "        \n",
    "        self.server_optimizer.zero_grad()\n",
    "        # iterate through each client and set gradients\n",
    "        for k, client in enumerate(self.clients.values()):\n",
    "            # skip clients with no optimizer\n",
    "            # we may want to use the weights of the local model instead\n",
    "            if client.optimizer is None:\n",
    "                continue\n",
    "            for group_server, group_client in zip(self.server_optimizer.param_groups, \n",
    "                                                  client.optimizer.param_groups):\n",
    "                for p_server, p_client in zip(group_server['params'], group_client['params']):\n",
    "                    if p_server.requires_grad:\n",
    "                        state = client.optimizer.state[p_client]\n",
    "                        w = self.client_weights[k]\n",
    "                        G_a = state['cgrad']\n",
    "                        a = torch.tensor(state['norm_factor'])\n",
    "                        d = G_a / a.abs().sum()\n",
    "                        tau_eff = client.local_steps\n",
    "                        if p_server.grad is None:\n",
    "                            p_server.grad = tau_eff * w * d  # need to take lr off of G ? jk lr is necessary for client (local)\n",
    "                        else:\n",
    "                            p_server.grad.data.add_(d, alpha=tau_eff * w)\n",
    "\n",
    "        self.server_optimizer.step()\n",
    "        \n",
    "        \n",
    "class FedDane(BaseFederater):\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 clients,\n",
    "                 client_optimizer_cls,\n",
    "                 client_optimizer_params,\n",
    "                 server_optimizer,\n",
    "                 mu=0,\n",
    "                 client_scheduler_cls=None,\n",
    "                 client_scheduler_params=None,\n",
    "                 server_scheduler=None,\n",
    "                 seed=None,\n",
    "                 writer=None):\n",
    "        super().__init__(model,\n",
    "                         clients,\n",
    "                         client_optimizer_cls,\n",
    "                         client_optimizer_params,\n",
    "                         server_optimizer=server_optimizer,\n",
    "                         server_scheduler=server_scheduler,\n",
    "                         client_scheduler_cls=client_scheduler_cls,\n",
    "                         client_scheduler_params=client_scheduler_params,\n",
    "                         seed=seed,\n",
    "                         writer=writer)\n",
    "        self.mu = mu\n",
    "        self.average_gradients = None\n",
    "            \n",
    "    def get_client_optimizer(self, client):\n",
    "        optimizer_params = self.client_optimizer_params or {}\n",
    "        client_optimizer = self.client_optimizer_cls(client.model.parameters(), **optimizer_params)\n",
    "        client_optimizer = FedDaneSolver(client_optimizer, \n",
    "                                         average_gradients=self.average_gradients,\n",
    "                                         mu=self.mu)\n",
    "        return client_optimizer\n",
    "    \n",
    "    def fit(self, \n",
    "            num_rounds,\n",
    "            criterion, \n",
    "            num_epochs,\n",
    "            val_dl=None,\n",
    "            C=0.1,\n",
    "            straggler_rate=0,\n",
    "            eval_every_n=1):\n",
    "        # subset a sample of `m` clients each round\n",
    "        m = max(int(np.ceil(self.num_clients * C)), 1)\n",
    "        \n",
    "        for t in range(num_rounds):\n",
    "            self.global_round += 1\n",
    "            \n",
    "            # calculate the average gradient on a subset of clients\n",
    "            S_grad = self._random_state.choice(self.client_ids, m, replace=False)\n",
    "            self.set_average_gradients(S_grad, criterion)\n",
    "            \n",
    "            # update a subset of clients with the local solver\n",
    "            S = self._random_state.choice(self.client_ids, m, replace=False)\n",
    "            train_metrics = self.update(client_ids=S, \n",
    "                                        criterion=criterion,\n",
    "                                        num_epochs=num_epochs, \n",
    "                                        straggler_rate=straggler_rate)\n",
    "            \n",
    "            if eval_every_n is not None and t % eval_every_n == 0:# and val_dl is not None:\n",
    "                template_str = f'round {self.global_round}'\n",
    "                val_metrics = self.validate(val_dl, criterion)\n",
    "                for metric, value in train_metrics.items():\n",
    "                    self.writer.add_scalar(f'train/{metric}', value, self.global_round)\n",
    "                    template_str += f' - train_{metric} : {value:0.4f}'\n",
    "                for metric, value in val_metrics.items():\n",
    "                    self.writer.add_scalar(f'val/{metric}', value, self.global_round)\n",
    "                    template_str += f' - val_{metric} : {value:0.4f}'\n",
    "                \n",
    "                print(template_str)\n",
    "    \n",
    "    def aggregate(self):\n",
    "        self.server_optimizer.zero_grad()\n",
    "        for k, client in enumerate(self.clients.values()):\n",
    "            for p_server, p_client in zip(self.model.parameters(), client.model.parameters()):\n",
    "                if p_server.requires_grad:\n",
    "                    if k == 0:\n",
    "                        p_server.grad = self.client_weights[k] * (p_server.data - p_client.data)\n",
    "                    else:\n",
    "                        p_server.grad.add_(p_server.data - p_client.data, alpha=self.client_weights[k])\n",
    "        \n",
    "        self.server_optimizer.step()\n",
    "        \n",
    "    def set_average_gradients(self, client_ids, criterion):\n",
    "        grads = self.get_gradients(client_ids, criterion)\n",
    "        average_gradients = [0] * len(grads[0])\n",
    "        for client_grads in grads:\n",
    "            for i, g in enumerate(client_grads):\n",
    "                average_gradients[i] += g\n",
    "        self.average_gradients = [g / len(grads) for g in average_gradients]\n",
    "        \n",
    "        \n",
    "        \n",
    "# scaffold.py\n",
    "class SCAFFOLD(BaseFederater):\n",
    "    \"\"\"SCAFFOLD\n",
    "    \n",
    "    https://arxiv.org/pdf/1910.06378.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 clients,\n",
    "                 client_optimizer_cls,\n",
    "                 client_optimizer_params,\n",
    "                 server_optimizer,\n",
    "                 option='II',\n",
    "                 client_scheduler_cls=None,\n",
    "                 client_scheduler_params=None,\n",
    "                 server_scheduler=None,\n",
    "                 seed=None,\n",
    "                 writer=None):\n",
    "        super().__init__(model,\n",
    "                         clients,\n",
    "                         client_optimizer_cls,\n",
    "                         client_optimizer_params,\n",
    "                         server_optimizer=server_optimizer,\n",
    "                         server_scheduler=server_scheduler,\n",
    "                         client_scheduler_cls=client_scheduler_cls,\n",
    "                         client_scheduler_params=client_scheduler_params,\n",
    "                         seed=seed,\n",
    "                         writer=writer)\n",
    "        self.option = option\n",
    "        self.control_server = [torch.zeros_like(p.data) for p in model.parameters()]\n",
    "\n",
    "    def send_model(self, client_ids=None):\n",
    "        \"\"\"Send the current state of the global model to each client.\"\"\"\n",
    "        if client_ids is None:\n",
    "            client_ids = self.client_ids\n",
    "        for client_id in client_ids:\n",
    "            self.clients[client_id].model = deepcopy(self.model)\n",
    "            self.clients[client_id].control_server = self.control_server\n",
    "            \n",
    "    def get_client_optimizer(self, client):\n",
    "        optimizer_params = self.client_optimizer_params or {}\n",
    "        client_optimizer = self.client_optimizer_cls(client.model.parameters(), **optimizer_params)\n",
    "        client_optimizer = SCAFFOLDSolver(client_optimizer, \n",
    "                                          control_global=self.control_server, \n",
    "                                          control_local=client.control)\n",
    "        return client_optimizer\n",
    "    \n",
    "    def aggregate(self):\n",
    "        # (5) update global parameters\n",
    "        self.server_optimizer.zero_grad()\n",
    "        for k, client in enumerate(self.clients.values()):\n",
    "            for p_server, p_client, c_client in zip(self.model.parameters(), client.model.parameters(), client.control):\n",
    "                if p_server.requires_grad:\n",
    "                    if k == 0:\n",
    "                        p_server.grad = self.client_weights[k] * (p_server.data - p_client.data)\n",
    "                    else:\n",
    "                        p_server.grad.data.add_(p_server.data - p_client.data, alpha=self.client_weights[k])\n",
    "        \n",
    "        self.server_optimizer.step()\n",
    "        \n",
    "        # (5) update global control variate\n",
    "        for client in self.clients.values():\n",
    "            for c, ci_delta in zip(self.control_server, client.control_delta):\n",
    "                c.data.add_(ci_delta, 1/self.num_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00056244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    fed_avg = {\n",
    "        'mnist': {\n",
    "            'clients': {\n",
    "                'num_clients': 100,\n",
    "                'shard_size': 300,\n",
    "                'batch_size': 10,\n",
    "                'is_iid': False,\n",
    "            },\n",
    "            'client_optimizer': 'SGD',\n",
    "            'client_optimizer_params': {\n",
    "                'lr': 0.1,\n",
    "            },\n",
    "            'federater': {\n",
    "                'C': 0.1\n",
    "            },\n",
    "            'fit': {\n",
    "                'num_rounds': 240,\n",
    "                'num_epochs': 20\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    fed_prox = {\n",
    "        'mnist': {\n",
    "            'clients': {\n",
    "                'num_clients': 100,\n",
    "                'shard_size': 300,\n",
    "                'batch_size': 10,\n",
    "                'is_iid': False,\n",
    "            },\n",
    "            'client_optimizer': 'SGD',\n",
    "            'client_optimizer_params': {\n",
    "                'lr': 0.03,\n",
    "            },\n",
    "            'federater': {\n",
    "                'C': 0.1,\n",
    "                'mu': 0.1\n",
    "            },\n",
    "            'fit': {\n",
    "                'num_rounds': 1,\n",
    "                'num_epochs': 1,\n",
    "#                 'straggler_rate': 0.5,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# config = Config()\n",
    "config = {\n",
    "    'fedavg': {\n",
    "        'mnist': {\n",
    "            'clients': {\n",
    "                'num_clients': 100,\n",
    "                'shard_size': 300,\n",
    "                'batch_size': 10,\n",
    "                'is_iid': True,\n",
    "            },\n",
    "            'client_optimizer': 'SGD',\n",
    "            'client_optimizer_params': {\n",
    "                'lr': 0.1,\n",
    "            },\n",
    "            'federater': {\n",
    "                'C': 0.1\n",
    "            },\n",
    "            'fit': {\n",
    "                'num_rounds': 50,\n",
    "                'num_epochs': 20\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'fedprox': {\n",
    "        'femnist': {\n",
    "            'input': {\n",
    "                'train': '/workspace/leaf/FedProx/data/nist/data/train/train.json',\n",
    "                'test': '/workspace/leaf/FedProx/data/nist/data/test/test.json',\n",
    "            },\n",
    "            'data': {\n",
    "                'batch_size': 10,\n",
    "                'num_workers': 0,\n",
    "            },\n",
    "            'client': {\n",
    "                'device': 'cpu'\n",
    "            },\n",
    "            'model': {\n",
    "                'name': 'lr',\n",
    "                'params': {\n",
    "                    'in_features': 784,\n",
    "                    'num_classes': 10\n",
    "                }\n",
    "            },\n",
    "            'server_optimizer': 'SGD',\n",
    "            'server_optimizer_params': {\n",
    "                'lr': 1\n",
    "            },\n",
    "            'client_optimizer': 'SGD',\n",
    "            'client_optimizer_params': {\n",
    "                'lr': 0.003,\n",
    "            },\n",
    "            'federater': {\n",
    "                'mu': 0.1\n",
    "            },\n",
    "            'fit': {\n",
    "                'num_rounds': 100,\n",
    "                'num_epochs': 20,\n",
    "                'C': 0.1,\n",
    "#                 'straggler_rate': 0.5,\n",
    "            }\n",
    "        },\n",
    "        'mnist': {\n",
    "            'clients': {\n",
    "                'num_clients': 100,\n",
    "                'shard_size': 300,\n",
    "                'batch_size': 10,\n",
    "                'is_iid': False,\n",
    "            },\n",
    "            'server_optimizer': 'SGD',\n",
    "            'server_optimizer_params': {\n",
    "                'lr': 1\n",
    "            },\n",
    "            'client_optimizer': 'SGD',\n",
    "            'client_optimizer_params': {\n",
    "                'lr': 0.03,\n",
    "            },\n",
    "            'federater': {\n",
    "                'C': 0.1,\n",
    "                'mu': 0.1\n",
    "            },\n",
    "            'fit': {\n",
    "                'num_rounds': 100,\n",
    "                'num_epochs': 20,\n",
    "#                 'straggler_rate': 0.5,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'fedadam': {\n",
    "        'mnist': {\n",
    "            'clients': {\n",
    "                'num_clients': 100,\n",
    "                'shard_size': 300,\n",
    "                'batch_size': 10,\n",
    "                'is_iid': False,\n",
    "            },\n",
    "            'client_optimizer': 'SGD',\n",
    "            'client_optimizer_params': {\n",
    "                'lr': 0.01,\n",
    "            },\n",
    "            'server_optimizer': 'adam',\n",
    "            'server_optimizer_params': {\n",
    "                'lr': 1,\n",
    "            },\n",
    "            'federater': {\n",
    "                'C': 0.1\n",
    "            },\n",
    "            'fit': {\n",
    "                'num_rounds': 240,\n",
    "                'num_epochs': 20\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0a55fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = datasets.fetch_openml('mnist_784', data_home='tmp')\n",
    "# from tqdm import trange\n",
    "# import numpy as np\n",
    "# import random\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# mu = np.mean(mnist.data.astype(np.float32), 0)\n",
    "# sigma = np.std(mnist.data.astype(np.float32), 0)\n",
    "# mnist.data = (mnist.data.astype(np.float32) - mu)/(sigma+0.001)\n",
    "# mnist.target = mnist.target.astype(np.int32)\n",
    "# mnist_data = []\n",
    "# for i in trange(10):\n",
    "#     idx = mnist.target==i\n",
    "#     mnist_data.append(mnist.data[idx])\n",
    "\n",
    "# print([len(v) for v in mnist_data])\n",
    "\n",
    "# ###### CREATE USER DATA SPLIT #######\n",
    "# # Assign 10 samples to each user\n",
    "# X = [[] for _ in range(1000)]\n",
    "# y = [[] for _ in range(1000)]\n",
    "# idx = np.zeros(10, dtype=np.int64)\n",
    "# for user in range(1000):\n",
    "#     for j in range(2):\n",
    "#         l = (user+j)%10\n",
    "#         X[user] += mnist_data[l][idx[l]:idx[l]+5].tolist()\n",
    "#         y[user] += (l*np.ones(5)).tolist()\n",
    "#         idx[l] += 5\n",
    "# print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b20acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def create_experiment_name(method, dataset, params=None):\n",
    "    params = params or {}\n",
    "    experiment_name = f'{method}_{dataset}'\n",
    "    if params.get('clients'):\n",
    "        if params['clients'].get('is_iid'):\n",
    "            if params['clients']['is_iid']:\n",
    "                experiment_name += \"_iid\"\n",
    "            else:\n",
    "                experiment_name += \"_noniid\"\n",
    "        if params['clients'].get('num_clients'):\n",
    "            experiment_name += f\"_K={params['clients']['num_clients']}\"\n",
    "        if params['clients'].get('batch_size'):\n",
    "            experiment_name += f\"_B={params['clients']['batch_size']}\"\n",
    "    if params.get('fit'):\n",
    "        if params['fit'].get('num_rounds'):\n",
    "            experiment_name += f\"_T={params['fit']['num_rounds']}\"\n",
    "        if params['fit'].get('num_epochs'):\n",
    "            experiment_name += f\"_E={params['fit']['num_epochs']}\"\n",
    "    if params.get('server_optimizer'):\n",
    "            experiment_name += f\"_SOPT={params['server_optimizer']}\"\n",
    "    if params.get('client_optimizer'):\n",
    "        experiment_name += f\"_COPT={params['client_optimizer']}\"\n",
    "    \n",
    "    experiment_name += f\"_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    return experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee2cb8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path=None):\n",
    "    with open(train_path, 'r') as f:\n",
    "        cdata = json.load(f)\n",
    "    train_data = cdata['user_data']\n",
    "    if test_path is not None:\n",
    "        with open(test_path, 'r') as f:\n",
    "            cdata = json.load(f)\n",
    "        test_data = cdata['user_data']\n",
    "    else:\n",
    "        test_data = None\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "143261a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fedprox baseline\n",
    "method = 'fedprox'\n",
    "dataset = 'femnist'\n",
    "seed = 42069\n",
    "device = 'cpu'\n",
    "num_workers = 0\n",
    "\n",
    "experiment_config = config[method][dataset]\n",
    "\n",
    "# load train, test data\n",
    "train_data, test_data = load_data(experiment_config['input']['train'], experiment_config['input'].get('test'))\n",
    "\n",
    "# setup clients\n",
    "client_params = config[method][dataset]['client']\n",
    "data_params = experiment_config.get('data', {})\n",
    "data_params['num_workers'] = num_workers\n",
    "clients = get_clients(\n",
    "    train_data,\n",
    "    test_data=test_data,\n",
    "    dataloader_params=data_params,\n",
    "    client_params=client_params\n",
    ")\n",
    "client_ids = list(clients.keys())\n",
    "\n",
    "# model\n",
    "model_cls = MODEL_MAP[experiment_config['model']['name']]\n",
    "model_params = experiment_config['model'].get('params', {})\n",
    "model = model_cls(**model_params)\n",
    "# model = MODEL_MAP[experiment_config['model']['name']](**experiment_config['model'].get('params', {}))\n",
    "\n",
    "# local and global optimizers\n",
    "client_optimizer_cls = getattr(torch.optim, experiment_config['client_optimizer'])\n",
    "client_optimizer_params = experiment_config['client_optimizer_params']\n",
    "server_optimizer = getattr(torch.optim, experiment_config['server_optimizer'])\n",
    "server_optimizer = server_optimizer(model.parameters(), **experiment_config['server_optimizer_params'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fed_params = experiment_config['federater']\n",
    "fed_params['seed'] = seed\n",
    "num_rounds = experiment_config['fit']['num_rounds']\n",
    "num_epochs = experiment_config['fit']['num_epochs']\n",
    "\n",
    "federater = FedProx(model,\n",
    "                   clients=clients,\n",
    "                    server_optimizer=server_optimizer,\n",
    "                   client_optimizer_cls=client_optimizer_cls,\n",
    "                   client_optimizer_params=client_optimizer_params,\n",
    "                   **fed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d85a9a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1 - 2s - train_loss : 0.9055 - train_accuracy : 0.6258 - val_loss : 2.3749 - val_accuracy : 0.0942\n",
      "round 2 - 4s - train_loss : 0.9401 - train_accuracy : 0.6233 - val_loss : 2.3417 - val_accuracy : 0.0942\n",
      "round 3 - 6s - train_loss : 0.9697 - train_accuracy : 0.5578 - val_loss : 2.3286 - val_accuracy : 0.0942\n",
      "round 4 - 7s - train_loss : 0.9068 - train_accuracy : 0.6143 - val_loss : 2.3082 - val_accuracy : 0.0942\n",
      "round 5 - 9s - train_loss : 0.9643 - train_accuracy : 0.5669 - val_loss : 2.2878 - val_accuracy : 0.0942\n",
      "round 6 - 11s - train_loss : 0.9021 - train_accuracy : 0.6570 - val_loss : 2.2488 - val_accuracy : 0.1047\n",
      "round 7 - 13s - train_loss : 0.8931 - train_accuracy : 0.6553 - val_loss : 2.2412 - val_accuracy : 0.1011\n",
      "round 8 - 14s - train_loss : 0.9007 - train_accuracy : 0.6290 - val_loss : 2.2362 - val_accuracy : 0.1360\n",
      "round 9 - 15s - train_loss : 0.9278 - train_accuracy : 0.6106 - val_loss : 2.2199 - val_accuracy : 0.1467\n",
      "round 10 - 17s - train_loss : 0.8751 - train_accuracy : 0.6358 - val_loss : 2.2137 - val_accuracy : 0.1849\n",
      "round 11 - 18s - train_loss : 0.9067 - train_accuracy : 0.6613 - val_loss : 2.2116 - val_accuracy : 0.1767\n",
      "round 12 - 20s - train_loss : 0.8832 - train_accuracy : 0.6381 - val_loss : 2.2137 - val_accuracy : 0.3072\n",
      "round 13 - 21s - train_loss : 0.8809 - train_accuracy : 0.6732 - val_loss : 2.1965 - val_accuracy : 0.3110\n",
      "round 14 - 23s - train_loss : 0.8953 - train_accuracy : 0.6464 - val_loss : 2.1902 - val_accuracy : 0.3082\n",
      "round 15 - 24s - train_loss : 0.8921 - train_accuracy : 0.6503 - val_loss : 2.1861 - val_accuracy : 0.2788\n",
      "round 16 - 26s - train_loss : 0.8928 - train_accuracy : 0.6565 - val_loss : 2.1625 - val_accuracy : 0.2811\n",
      "round 17 - 27s - train_loss : 0.8536 - train_accuracy : 0.6682 - val_loss : 2.1406 - val_accuracy : 0.3374\n",
      "round 18 - 29s - train_loss : 0.8794 - train_accuracy : 0.6615 - val_loss : 2.1412 - val_accuracy : 0.2907\n",
      "round 19 - 30s - train_loss : 0.8328 - train_accuracy : 0.7245 - val_loss : 2.1368 - val_accuracy : 0.3048\n",
      "round 20 - 32s - train_loss : 0.8495 - train_accuracy : 0.6920 - val_loss : 2.1367 - val_accuracy : 0.2971\n",
      "round 21 - 33s - train_loss : 0.8485 - train_accuracy : 0.7264 - val_loss : 2.1128 - val_accuracy : 0.3324\n",
      "round 22 - 35s - train_loss : 0.8340 - train_accuracy : 0.6753 - val_loss : 2.0949 - val_accuracy : 0.3762\n",
      "round 23 - 37s - train_loss : 0.8027 - train_accuracy : 0.6999 - val_loss : 2.1020 - val_accuracy : 0.3350\n",
      "round 24 - 38s - train_loss : 0.8494 - train_accuracy : 0.7123 - val_loss : 2.0826 - val_accuracy : 0.3731\n",
      "round 25 - 39s - train_loss : 0.8456 - train_accuracy : 0.6938 - val_loss : 2.0749 - val_accuracy : 0.3524\n",
      "round 26 - 40s - train_loss : 0.7829 - train_accuracy : 0.7582 - val_loss : 2.0667 - val_accuracy : 0.3436\n",
      "round 27 - 42s - train_loss : 0.8122 - train_accuracy : 0.7070 - val_loss : 2.0525 - val_accuracy : 0.4173\n",
      "round 28 - 43s - train_loss : 0.7979 - train_accuracy : 0.7172 - val_loss : 2.0492 - val_accuracy : 0.3985\n",
      "round 29 - 45s - train_loss : 0.7757 - train_accuracy : 0.7210 - val_loss : 2.0500 - val_accuracy : 0.2982\n",
      "round 30 - 47s - train_loss : 0.7904 - train_accuracy : 0.7358 - val_loss : 2.0401 - val_accuracy : 0.2907\n",
      "round 31 - 49s - train_loss : 0.7526 - train_accuracy : 0.7816 - val_loss : 2.0217 - val_accuracy : 0.3372\n",
      "round 32 - 50s - train_loss : 0.8036 - train_accuracy : 0.7277 - val_loss : 2.0143 - val_accuracy : 0.3856\n",
      "round 33 - 52s - train_loss : 0.7585 - train_accuracy : 0.7600 - val_loss : 2.0066 - val_accuracy : 0.3606\n",
      "round 34 - 54s - train_loss : 0.7592 - train_accuracy : 0.7738 - val_loss : 1.9945 - val_accuracy : 0.4567\n",
      "round 35 - 55s - train_loss : 0.7616 - train_accuracy : 0.7523 - val_loss : 1.9983 - val_accuracy : 0.3623\n",
      "round 36 - 57s - train_loss : 0.7578 - train_accuracy : 0.8022 - val_loss : 1.9954 - val_accuracy : 0.3351\n",
      "round 37 - 58s - train_loss : 0.7659 - train_accuracy : 0.7685 - val_loss : 1.9986 - val_accuracy : 0.3299\n",
      "round 38 - 59s - train_loss : 0.7746 - train_accuracy : 0.7573 - val_loss : 1.9957 - val_accuracy : 0.3231\n",
      "round 39 - 61s - train_loss : 0.7395 - train_accuracy : 0.8218 - val_loss : 2.0379 - val_accuracy : 0.2683\n",
      "round 40 - 63s - train_loss : 0.7653 - train_accuracy : 0.7677 - val_loss : 2.0073 - val_accuracy : 0.2844\n",
      "round 41 - 64s - train_loss : 0.7346 - train_accuracy : 0.7777 - val_loss : 1.9796 - val_accuracy : 0.2994\n",
      "round 42 - 66s - train_loss : 0.7287 - train_accuracy : 0.7927 - val_loss : 1.9617 - val_accuracy : 0.3236\n",
      "round 43 - 67s - train_loss : 0.7444 - train_accuracy : 0.7748 - val_loss : 1.9374 - val_accuracy : 0.4085\n",
      "round 44 - 69s - train_loss : 0.7396 - train_accuracy : 0.7919 - val_loss : 1.9288 - val_accuracy : 0.4111\n",
      "round 45 - 71s - train_loss : 0.6870 - train_accuracy : 0.8146 - val_loss : 1.9389 - val_accuracy : 0.3275\n",
      "round 46 - 73s - train_loss : 0.7346 - train_accuracy : 0.7626 - val_loss : 1.9407 - val_accuracy : 0.3173\n",
      "round 47 - 74s - train_loss : 0.7120 - train_accuracy : 0.7637 - val_loss : 1.9649 - val_accuracy : 0.2678\n",
      "round 48 - 76s - train_loss : 0.7565 - train_accuracy : 0.7566 - val_loss : 1.9549 - val_accuracy : 0.2896\n",
      "round 49 - 77s - train_loss : 0.6997 - train_accuracy : 0.8177 - val_loss : 1.9418 - val_accuracy : 0.3172\n",
      "round 50 - 79s - train_loss : 0.7038 - train_accuracy : 0.8240 - val_loss : 1.9337 - val_accuracy : 0.3146\n",
      "round 51 - 80s - train_loss : 0.6864 - train_accuracy : 0.8115 - val_loss : 1.9306 - val_accuracy : 0.3272\n",
      "round 52 - 82s - train_loss : 0.7062 - train_accuracy : 0.7948 - val_loss : 1.9479 - val_accuracy : 0.2909\n",
      "round 53 - 83s - train_loss : 0.7048 - train_accuracy : 0.7927 - val_loss : 1.9385 - val_accuracy : 0.3143\n",
      "round 54 - 85s - train_loss : 0.6498 - train_accuracy : 0.8196 - val_loss : 1.9339 - val_accuracy : 0.2903\n",
      "round 55 - 87s - train_loss : 0.6907 - train_accuracy : 0.8065 - val_loss : 1.9071 - val_accuracy : 0.3164\n",
      "round 56 - 88s - train_loss : 0.6549 - train_accuracy : 0.8291 - val_loss : 1.9113 - val_accuracy : 0.3123\n",
      "round 57 - 90s - train_loss : 0.7035 - train_accuracy : 0.7877 - val_loss : 1.8743 - val_accuracy : 0.3528\n",
      "round 58 - 92s - train_loss : 0.6803 - train_accuracy : 0.7961 - val_loss : 1.8865 - val_accuracy : 0.3275\n",
      "round 59 - 94s - train_loss : 0.6811 - train_accuracy : 0.7882 - val_loss : 1.8860 - val_accuracy : 0.3188\n",
      "round 60 - 96s - train_loss : 0.6171 - train_accuracy : 0.8406 - val_loss : 1.8775 - val_accuracy : 0.3359\n",
      "round 61 - 98s - train_loss : 0.6370 - train_accuracy : 0.8448 - val_loss : 1.8783 - val_accuracy : 0.3390\n",
      "round 62 - 100s - train_loss : 0.6948 - train_accuracy : 0.8071 - val_loss : 1.8700 - val_accuracy : 0.3403\n",
      "round 63 - 101s - train_loss : 0.6734 - train_accuracy : 0.8109 - val_loss : 1.8646 - val_accuracy : 0.3402\n",
      "round 64 - 102s - train_loss : 0.6618 - train_accuracy : 0.8138 - val_loss : 1.8389 - val_accuracy : 0.3679\n",
      "round 65 - 104s - train_loss : 0.6802 - train_accuracy : 0.8063 - val_loss : 1.8233 - val_accuracy : 0.4152\n",
      "round 66 - 105s - train_loss : 0.6545 - train_accuracy : 0.8363 - val_loss : 1.8295 - val_accuracy : 0.3723\n",
      "round 67 - 107s - train_loss : 0.6735 - train_accuracy : 0.8158 - val_loss : 1.8318 - val_accuracy : 0.3960\n",
      "round 68 - 108s - train_loss : 0.6572 - train_accuracy : 0.8202 - val_loss : 1.8161 - val_accuracy : 0.4716\n",
      "round 69 - 110s - train_loss : 0.5979 - train_accuracy : 0.8617 - val_loss : 1.8310 - val_accuracy : 0.3525\n",
      "round 70 - 112s - train_loss : 0.6243 - train_accuracy : 0.8309 - val_loss : 1.8276 - val_accuracy : 0.3439\n",
      "round 71 - 113s - train_loss : 0.6218 - train_accuracy : 0.8275 - val_loss : 1.8163 - val_accuracy : 0.3483\n",
      "round 72 - 115s - train_loss : 0.6490 - train_accuracy : 0.8374 - val_loss : 1.7993 - val_accuracy : 0.3645\n",
      "round 73 - 117s - train_loss : 0.6326 - train_accuracy : 0.8420 - val_loss : 1.7891 - val_accuracy : 0.3981\n",
      "round 74 - 118s - train_loss : 0.6427 - train_accuracy : 0.8337 - val_loss : 1.7948 - val_accuracy : 0.3830\n",
      "round 75 - 119s - train_loss : 0.6286 - train_accuracy : 0.8199 - val_loss : 1.7865 - val_accuracy : 0.4102\n",
      "round 76 - 121s - train_loss : 0.6097 - train_accuracy : 0.8504 - val_loss : 1.7820 - val_accuracy : 0.3989\n",
      "round 77 - 123s - train_loss : 0.6202 - train_accuracy : 0.8405 - val_loss : 1.7937 - val_accuracy : 0.3477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 78 - 125s - train_loss : 0.6233 - train_accuracy : 0.8489 - val_loss : 1.7860 - val_accuracy : 0.3670\n",
      "round 79 - 126s - train_loss : 0.6170 - train_accuracy : 0.8196 - val_loss : 1.7646 - val_accuracy : 0.4316\n",
      "round 80 - 127s - train_loss : 0.5955 - train_accuracy : 0.8890 - val_loss : 1.7808 - val_accuracy : 0.3480\n",
      "round 81 - 129s - train_loss : 0.6225 - train_accuracy : 0.8641 - val_loss : 1.7519 - val_accuracy : 0.3818\n",
      "round 82 - 131s - train_loss : 0.5551 - train_accuracy : 0.8749 - val_loss : 1.7238 - val_accuracy : 0.5116\n",
      "round 83 - 133s - train_loss : 0.6195 - train_accuracy : 0.8415 - val_loss : 1.7247 - val_accuracy : 0.4604\n",
      "round 84 - 134s - train_loss : 0.5894 - train_accuracy : 0.8436 - val_loss : 1.7186 - val_accuracy : 0.4660\n",
      "round 85 - 136s - train_loss : 0.5940 - train_accuracy : 0.8680 - val_loss : 1.7182 - val_accuracy : 0.4800\n",
      "round 86 - 137s - train_loss : 0.6244 - train_accuracy : 0.8406 - val_loss : 1.7088 - val_accuracy : 0.5405\n",
      "round 87 - 139s - train_loss : 0.6217 - train_accuracy : 0.8283 - val_loss : 1.7058 - val_accuracy : 0.5160\n",
      "round 88 - 140s - train_loss : 0.5823 - train_accuracy : 0.8646 - val_loss : 1.7033 - val_accuracy : 0.4816\n",
      "round 89 - 142s - train_loss : 0.5772 - train_accuracy : 0.8556 - val_loss : 1.7130 - val_accuracy : 0.4380\n",
      "round 90 - 144s - train_loss : 0.6084 - train_accuracy : 0.8410 - val_loss : 1.6969 - val_accuracy : 0.4671\n",
      "round 91 - 145s - train_loss : 0.5697 - train_accuracy : 0.8554 - val_loss : 1.6950 - val_accuracy : 0.4678\n",
      "round 92 - 147s - train_loss : 0.5854 - train_accuracy : 0.8540 - val_loss : 1.6836 - val_accuracy : 0.5050\n",
      "round 93 - 149s - train_loss : 0.5709 - train_accuracy : 0.8714 - val_loss : 1.6848 - val_accuracy : 0.4826\n",
      "round 94 - 150s - train_loss : 0.6206 - train_accuracy : 0.8367 - val_loss : 1.6676 - val_accuracy : 0.5184\n",
      "round 95 - 152s - train_loss : 0.6186 - train_accuracy : 0.8478 - val_loss : 1.6760 - val_accuracy : 0.4840\n",
      "round 96 - 154s - train_loss : 0.5409 - train_accuracy : 0.8392 - val_loss : 1.6732 - val_accuracy : 0.4939\n",
      "round 97 - 156s - train_loss : 0.5426 - train_accuracy : 0.8826 - val_loss : 1.6997 - val_accuracy : 0.4048\n",
      "round 98 - 158s - train_loss : 0.5783 - train_accuracy : 0.8474 - val_loss : 1.7191 - val_accuracy : 0.3579\n",
      "round 99 - 159s - train_loss : 0.5987 - train_accuracy : 0.8657 - val_loss : 1.7163 - val_accuracy : 0.3718\n",
      "round 100 - 161s - train_loss : 0.5581 - train_accuracy : 0.8660 - val_loss : 1.6838 - val_accuracy : 0.3901\n"
     ]
    }
   ],
   "source": [
    "federater.fit(criterion=criterion, **experiment_config['fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3494fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 101 - 1s - train_loss : 0.5449 - train_accuracy : 0.8582 - val_loss : 1.6673 - val_accuracy : 0.4689\n",
      "round 102 - 3s - train_loss : 0.5924 - train_accuracy : 0.8196 - val_loss : 1.6721 - val_accuracy : 0.4950\n",
      "round 103 - 5s - train_loss : 0.5501 - train_accuracy : 0.8806 - val_loss : 1.6710 - val_accuracy : 0.4557\n",
      "round 104 - 6s - train_loss : 0.6096 - train_accuracy : 0.8425 - val_loss : 1.6386 - val_accuracy : 0.5502\n",
      "round 105 - 8s - train_loss : 0.6015 - train_accuracy : 0.8306 - val_loss : 1.6216 - val_accuracy : 0.6038\n",
      "round 106 - 10s - train_loss : 0.5222 - train_accuracy : 0.8915 - val_loss : 1.6298 - val_accuracy : 0.5561\n",
      "round 107 - 12s - train_loss : 0.5766 - train_accuracy : 0.8553 - val_loss : 1.6109 - val_accuracy : 0.6095\n",
      "round 108 - 13s - train_loss : 0.5466 - train_accuracy : 0.8688 - val_loss : 1.6053 - val_accuracy : 0.6026\n",
      "round 109 - 15s - train_loss : 0.5252 - train_accuracy : 0.8836 - val_loss : 1.6141 - val_accuracy : 0.5506\n",
      "round 110 - 16s - train_loss : 0.5429 - train_accuracy : 0.8834 - val_loss : 1.6064 - val_accuracy : 0.5532\n",
      "round 111 - 18s - train_loss : 0.5604 - train_accuracy : 0.8600 - val_loss : 1.5953 - val_accuracy : 0.5850\n",
      "round 112 - 19s - train_loss : 0.5279 - train_accuracy : 0.9035 - val_loss : 1.6037 - val_accuracy : 0.5559\n",
      "round 113 - 21s - train_loss : 0.5846 - train_accuracy : 0.8553 - val_loss : 1.6058 - val_accuracy : 0.5479\n",
      "round 114 - 22s - train_loss : 0.5590 - train_accuracy : 0.8395 - val_loss : 1.6058 - val_accuracy : 0.5334\n",
      "round 115 - 24s - train_loss : 0.5240 - train_accuracy : 0.8916 - val_loss : 1.6420 - val_accuracy : 0.4273\n",
      "round 116 - 26s - train_loss : 0.5198 - train_accuracy : 0.8548 - val_loss : 1.6871 - val_accuracy : 0.3594\n",
      "round 117 - 28s - train_loss : 0.5886 - train_accuracy : 0.8580 - val_loss : 1.6650 - val_accuracy : 0.3875\n",
      "round 118 - 29s - train_loss : 0.5507 - train_accuracy : 0.8374 - val_loss : 1.6629 - val_accuracy : 0.3518\n",
      "round 119 - 30s - train_loss : 0.5752 - train_accuracy : 0.8500 - val_loss : 1.6169 - val_accuracy : 0.4259\n",
      "round 120 - 32s - train_loss : 0.5246 - train_accuracy : 0.8531 - val_loss : 1.5926 - val_accuracy : 0.5050\n",
      "round 121 - 34s - train_loss : 0.5445 - train_accuracy : 0.8602 - val_loss : 1.5826 - val_accuracy : 0.5249\n",
      "round 122 - 35s - train_loss : 0.5236 - train_accuracy : 0.8551 - val_loss : 1.5806 - val_accuracy : 0.5220\n",
      "round 123 - 37s - train_loss : 0.5021 - train_accuracy : 0.8852 - val_loss : 1.5830 - val_accuracy : 0.5099\n",
      "round 124 - 39s - train_loss : 0.5082 - train_accuracy : 0.8766 - val_loss : 1.5616 - val_accuracy : 0.5486\n",
      "round 125 - 40s - train_loss : 0.5314 - train_accuracy : 0.8723 - val_loss : 1.5478 - val_accuracy : 0.5921\n",
      "round 126 - 42s - train_loss : 0.5451 - train_accuracy : 0.8411 - val_loss : 1.5377 - val_accuracy : 0.6363\n",
      "round 127 - 43s - train_loss : 0.5205 - train_accuracy : 0.8641 - val_loss : 1.5332 - val_accuracy : 0.6419\n",
      "round 128 - 45s - train_loss : 0.5190 - train_accuracy : 0.8898 - val_loss : 1.5426 - val_accuracy : 0.6145\n",
      "round 129 - 46s - train_loss : 0.5407 - train_accuracy : 0.8675 - val_loss : 1.5320 - val_accuracy : 0.6405\n",
      "round 130 - 49s - train_loss : 0.5240 - train_accuracy : 0.8673 - val_loss : 1.5449 - val_accuracy : 0.5673\n",
      "round 131 - 50s - train_loss : 0.5262 - train_accuracy : 0.8778 - val_loss : 1.5494 - val_accuracy : 0.5557\n",
      "round 132 - 52s - train_loss : 0.4999 - train_accuracy : 0.8931 - val_loss : 1.5883 - val_accuracy : 0.4749\n",
      "round 133 - 54s - train_loss : 0.5122 - train_accuracy : 0.8913 - val_loss : 1.5482 - val_accuracy : 0.5457\n",
      "round 134 - 55s - train_loss : 0.5122 - train_accuracy : 0.8844 - val_loss : 1.5320 - val_accuracy : 0.5699\n",
      "round 135 - 57s - train_loss : 0.4798 - train_accuracy : 0.8874 - val_loss : 1.5367 - val_accuracy : 0.5555\n",
      "round 136 - 58s - train_loss : 0.4669 - train_accuracy : 0.8669 - val_loss : 1.5357 - val_accuracy : 0.5640\n",
      "round 137 - 59s - train_loss : 0.5128 - train_accuracy : 0.8804 - val_loss : 1.5404 - val_accuracy : 0.5478\n",
      "round 138 - 61s - train_loss : 0.5032 - train_accuracy : 0.8773 - val_loss : 1.5132 - val_accuracy : 0.6207\n",
      "round 139 - 63s - train_loss : 0.4801 - train_accuracy : 0.8838 - val_loss : 1.5145 - val_accuracy : 0.5934\n",
      "round 140 - 64s - train_loss : 0.5212 - train_accuracy : 0.8752 - val_loss : 1.5071 - val_accuracy : 0.5965\n",
      "round 141 - 66s - train_loss : 0.4822 - train_accuracy : 0.8846 - val_loss : 1.5446 - val_accuracy : 0.5194\n",
      "round 142 - 68s - train_loss : 0.4991 - train_accuracy : 0.8747 - val_loss : 1.5603 - val_accuracy : 0.4989\n",
      "round 143 - 70s - train_loss : 0.5008 - train_accuracy : 0.8816 - val_loss : 1.5510 - val_accuracy : 0.4934\n",
      "round 144 - 71s - train_loss : 0.4836 - train_accuracy : 0.8966 - val_loss : 1.5670 - val_accuracy : 0.4672\n",
      "round 145 - 73s - train_loss : 0.5244 - train_accuracy : 0.8560 - val_loss : 1.5264 - val_accuracy : 0.5100\n",
      "round 146 - 74s - train_loss : 0.5205 - train_accuracy : 0.8734 - val_loss : 1.5642 - val_accuracy : 0.4449\n",
      "round 147 - 76s - train_loss : 0.4632 - train_accuracy : 0.8934 - val_loss : 1.6299 - val_accuracy : 0.3813\n",
      "round 148 - 78s - train_loss : 0.5060 - train_accuracy : 0.8868 - val_loss : 1.5831 - val_accuracy : 0.4729\n",
      "round 149 - 79s - train_loss : 0.4908 - train_accuracy : 0.8702 - val_loss : 1.5861 - val_accuracy : 0.4930\n",
      "round 150 - 81s - train_loss : 0.4802 - train_accuracy : 0.8872 - val_loss : 1.5670 - val_accuracy : 0.4717\n",
      "round 151 - 82s - train_loss : 0.4329 - train_accuracy : 0.9029 - val_loss : 1.5749 - val_accuracy : 0.4902\n",
      "round 152 - 84s - train_loss : 0.4772 - train_accuracy : 0.8899 - val_loss : 1.5422 - val_accuracy : 0.4904\n",
      "round 153 - 86s - train_loss : 0.4472 - train_accuracy : 0.9113 - val_loss : 1.5869 - val_accuracy : 0.4799\n",
      "round 154 - 87s - train_loss : 0.4523 - train_accuracy : 0.8925 - val_loss : 1.5609 - val_accuracy : 0.4588\n",
      "round 155 - 89s - train_loss : 0.4771 - train_accuracy : 0.8945 - val_loss : 1.5596 - val_accuracy : 0.4619\n",
      "round 156 - 90s - train_loss : 0.4602 - train_accuracy : 0.8856 - val_loss : 1.6090 - val_accuracy : 0.4092\n",
      "round 157 - 92s - train_loss : 0.4561 - train_accuracy : 0.9038 - val_loss : 1.6372 - val_accuracy : 0.3742\n",
      "round 158 - 94s - train_loss : 0.4632 - train_accuracy : 0.8916 - val_loss : 1.5733 - val_accuracy : 0.4264\n",
      "round 159 - 95s - train_loss : 0.4346 - train_accuracy : 0.9255 - val_loss : 1.5875 - val_accuracy : 0.4100\n",
      "round 160 - 97s - train_loss : 0.4405 - train_accuracy : 0.9061 - val_loss : 1.5757 - val_accuracy : 0.4181\n",
      "round 161 - 98s - train_loss : 0.4980 - train_accuracy : 0.8715 - val_loss : 1.5364 - val_accuracy : 0.4573\n",
      "round 162 - 100s - train_loss : 0.4471 - train_accuracy : 0.8807 - val_loss : 1.5430 - val_accuracy : 0.4715\n",
      "round 163 - 101s - train_loss : 0.4888 - train_accuracy : 0.8781 - val_loss : 1.5161 - val_accuracy : 0.4817\n",
      "round 164 - 103s - train_loss : 0.4721 - train_accuracy : 0.8920 - val_loss : 1.5145 - val_accuracy : 0.4715\n",
      "round 165 - 104s - train_loss : 0.4447 - train_accuracy : 0.9039 - val_loss : 1.5171 - val_accuracy : 0.4622\n",
      "round 166 - 106s - train_loss : 0.4714 - train_accuracy : 0.8854 - val_loss : 1.4909 - val_accuracy : 0.4820\n",
      "round 167 - 108s - train_loss : 0.4189 - train_accuracy : 0.8888 - val_loss : 1.4860 - val_accuracy : 0.4966\n",
      "round 168 - 110s - train_loss : 0.4628 - train_accuracy : 0.8744 - val_loss : 1.4663 - val_accuracy : 0.5418\n",
      "round 169 - 112s - train_loss : 0.4792 - train_accuracy : 0.8735 - val_loss : 1.4386 - val_accuracy : 0.6064\n",
      "round 170 - 114s - train_loss : 0.4270 - train_accuracy : 0.9045 - val_loss : 1.4588 - val_accuracy : 0.5453\n",
      "round 171 - 116s - train_loss : 0.4402 - train_accuracy : 0.9081 - val_loss : 1.4489 - val_accuracy : 0.5765\n",
      "round 172 - 118s - train_loss : 0.4378 - train_accuracy : 0.9009 - val_loss : 1.4410 - val_accuracy : 0.5750\n",
      "round 173 - 119s - train_loss : 0.4512 - train_accuracy : 0.9007 - val_loss : 1.4297 - val_accuracy : 0.6146\n",
      "round 174 - 120s - train_loss : 0.4231 - train_accuracy : 0.9058 - val_loss : 1.4265 - val_accuracy : 0.6185\n",
      "round 175 - 122s - train_loss : 0.4689 - train_accuracy : 0.9006 - val_loss : 1.4212 - val_accuracy : 0.6343\n",
      "round 176 - 123s - train_loss : 0.4344 - train_accuracy : 0.8893 - val_loss : 1.4184 - val_accuracy : 0.6225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 177 - 124s - train_loss : 0.4672 - train_accuracy : 0.8706 - val_loss : 1.4157 - val_accuracy : 0.6344\n",
      "round 178 - 125s - train_loss : 0.4340 - train_accuracy : 0.9003 - val_loss : 1.4183 - val_accuracy : 0.6065\n",
      "round 179 - 127s - train_loss : 0.4423 - train_accuracy : 0.9041 - val_loss : 1.4109 - val_accuracy : 0.6416\n",
      "round 180 - 128s - train_loss : 0.4482 - train_accuracy : 0.8942 - val_loss : 1.4088 - val_accuracy : 0.6482\n",
      "round 181 - 130s - train_loss : 0.4544 - train_accuracy : 0.9050 - val_loss : 1.4189 - val_accuracy : 0.6317\n",
      "round 182 - 131s - train_loss : 0.4611 - train_accuracy : 0.8915 - val_loss : 1.4138 - val_accuracy : 0.6486\n",
      "round 183 - 133s - train_loss : 0.4256 - train_accuracy : 0.9108 - val_loss : 1.4036 - val_accuracy : 0.6434\n",
      "round 184 - 135s - train_loss : 0.4633 - train_accuracy : 0.8869 - val_loss : 1.4102 - val_accuracy : 0.6365\n",
      "round 185 - 136s - train_loss : 0.4486 - train_accuracy : 0.9046 - val_loss : 1.4067 - val_accuracy : 0.6600\n",
      "round 186 - 138s - train_loss : 0.4419 - train_accuracy : 0.8990 - val_loss : 1.4056 - val_accuracy : 0.6461\n",
      "round 187 - 140s - train_loss : 0.4376 - train_accuracy : 0.9047 - val_loss : 1.3923 - val_accuracy : 0.6622\n",
      "round 188 - 141s - train_loss : 0.4205 - train_accuracy : 0.8946 - val_loss : 1.3855 - val_accuracy : 0.6570\n",
      "round 189 - 143s - train_loss : 0.4323 - train_accuracy : 0.8958 - val_loss : 1.3946 - val_accuracy : 0.6129\n",
      "round 190 - 145s - train_loss : 0.4149 - train_accuracy : 0.9162 - val_loss : 1.3767 - val_accuracy : 0.6245\n",
      "round 191 - 147s - train_loss : 0.4546 - train_accuracy : 0.8874 - val_loss : 1.3828 - val_accuracy : 0.6295\n",
      "round 192 - 148s - train_loss : 0.4261 - train_accuracy : 0.9118 - val_loss : 1.3937 - val_accuracy : 0.5988\n",
      "round 193 - 149s - train_loss : 0.4371 - train_accuracy : 0.8873 - val_loss : 1.3945 - val_accuracy : 0.5908\n",
      "round 194 - 151s - train_loss : 0.4284 - train_accuracy : 0.8944 - val_loss : 1.3973 - val_accuracy : 0.5851\n",
      "round 195 - 153s - train_loss : 0.4512 - train_accuracy : 0.9020 - val_loss : 1.3806 - val_accuracy : 0.6293\n",
      "round 196 - 154s - train_loss : 0.4141 - train_accuracy : 0.9272 - val_loss : 1.3736 - val_accuracy : 0.6084\n",
      "round 197 - 156s - train_loss : 0.4384 - train_accuracy : 0.8904 - val_loss : 1.3803 - val_accuracy : 0.6032\n",
      "round 198 - 158s - train_loss : 0.4277 - train_accuracy : 0.9052 - val_loss : 1.3686 - val_accuracy : 0.6275\n",
      "round 199 - 159s - train_loss : 0.4095 - train_accuracy : 0.9168 - val_loss : 1.3755 - val_accuracy : 0.6362\n",
      "round 200 - 161s - train_loss : 0.4358 - train_accuracy : 0.8809 - val_loss : 1.3733 - val_accuracy : 0.6248\n"
     ]
    }
   ],
   "source": [
    "federater.fit(criterion=criterion, **experiment_config['fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecad0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518de2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "federater.fit(num_rounds=num_rounds, criterion=criterion, num_epochs=num_epochs, val_dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1fd5b796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.LogisticRegression"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MODEL_MAP[experiment_config['model']['name']](**experiment_config['model'].get('params', {}))\n",
    "client_optimizer_cls = getattr(torch.optim, experiment_config['client_optimizer'])\n",
    "client_optimizer_params = experiment_config['client_optimizer_params']\n",
    "server_optimizer = getattr(torch.optim, experiment_config['server_optimizer'])\n",
    "server_optimizer = server_optimizer(model.parameters(), **experiment_config['server_optimizer_params'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fed_params = experiment_config['federater']\n",
    "fed_params['seed'] = seed\n",
    "num_rounds = experiment_config['fit']['num_rounds']\n",
    "num_epochs = experiment_config['fit']['num_epochs']\n",
    "\n",
    "federater = FedProx(model,\n",
    "                   clients=clients,\n",
    "                    server_optimizer=server_optimizer,\n",
    "                   client_optimizer_cls=client_optimizer_cls,\n",
    "                   client_optimizer_params=client_optimizer_params,\n",
    "                   **fed_params)\n",
    "federater.fit(num_rounds=num_rounds, criterion=criterion, num_epochs=num_epochs, val_dl=test_dl)c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0054b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "client_optimizer_cls = getattr(torch.optim, config[method][dataset]['client_optimizer'])\n",
    "client_optimizer_params = config[method][dataset]['client_optimizer_params']\n",
    "server_optimizer = getattr(torch.optim, config[method][dataset]['server_optimizer'])\n",
    "server_optimizer = server_optimizer(model.parameters(), **config[method][dataset]['server_optimizer_params'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fed_params = config[method][dataset]['federater']\n",
    "fed_params['seed'] = seed\n",
    "num_rounds = config[method][dataset]['fit']['num_rounds']\n",
    "num_epochs = config[method][dataset]['fit']['num_epochs']\n",
    "\n",
    "federater = FedProx(model,\n",
    "                   clients=clients,\n",
    "                    server_optimizer=server_optimizer,\n",
    "                   client_optimizer_cls=client_optimizer_cls,\n",
    "                   client_optimizer_params=client_optimizer_params,\n",
    "                   **fed_params)\n",
    "federater.fit(num_rounds=num_rounds, criterion=criterion, num_epochs=num_epochs, val_dl=test_dl)c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6088908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment : tmp_prox\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-13a402342a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;36m0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mclient_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clients'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m clients = get_clients(\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Fedprox baseline\n",
    "method = 'fedprox'\n",
    "dataset = 'femnist'\n",
    "seed = 42069\n",
    "device = 'cpu'\n",
    "num_workers = 0\n",
    "\n",
    "# experiment_name = create_experiment_name(method, dataset, config[method][dataset])\n",
    "experiment_name = 'tmp_prox'\n",
    "print(f'Experiment : {experiment_name}')\n",
    "\n",
    "# writer = SummaryWriter(os.path.join('logs', experiment_name))\n",
    "writer = SummaryWriter()\n",
    "\n",
    "set_state(seed)\n",
    "0/0\n",
    "client_params = config[method][dataset]['clients']\n",
    "clients = get_clients(\n",
    "    train_ds, \n",
    "    num_workers=num_workers,\n",
    "    seed=seed,\n",
    "    device=device,\n",
    "    **client_params,\n",
    ")\n",
    "\n",
    "model = CNN()\n",
    "client_optimizer_cls = getattr(torch.optim, config[method][dataset]['client_optimizer'])\n",
    "client_optimizer_params = config[method][dataset]['client_optimizer_params']\n",
    "server_optimizer = getattr(torch.optim, config[method][dataset]['server_optimizer'])\n",
    "server_optimizer = server_optimizer(model.parameters(), **config[method][dataset]['server_optimizer_params'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fed_params = config[method][dataset]['federater']\n",
    "fed_params['seed'] = seed\n",
    "num_rounds = config[method][dataset]['fit']['num_rounds']\n",
    "num_epochs = config[method][dataset]['fit']['num_epochs']\n",
    "\n",
    "federater = FedProx(model,\n",
    "                   clients=clients,\n",
    "                    server_optimizer=server_optimizer,\n",
    "                   client_optimizer_cls=client_optimizer_cls,\n",
    "                   client_optimizer_params=client_optimizer_params,\n",
    "                   **fed_params)\n",
    "federater.fit(num_rounds=num_rounds, criterion=criterion, num_epochs=num_epochs, val_dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2553ce70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54877a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e9af4176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment : tmp\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 784, 5, 5], expected input[10, 1, 28, 28] to have 784 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-f6957d8f06c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mclient_optimizer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_optimizer_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     **fed_params)\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mfederater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-127-62c9c5122ac3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_rounds, criterion, num_epochs, val_dl, straggler_rate, eval_every_n)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# update a subset of clients with the local solver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             train_metrics = self.update(client_ids=S, \n\u001b[0m\u001b[1;32m    148\u001b[0m                                         \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                                         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-62c9c5122ac3>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, client_ids, criterion, num_epochs, straggler_rate)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# update the client weights and record the local training metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             client_metrics_dict = client.update(\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-3e02d27f4cd6>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-5790c38984d9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 784, 5, 5], expected input[10, 1, 28, 28] to have 784 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "# Fed avg baseline\n",
    "method = 'fedavg'\n",
    "dataset = 'mnist'\n",
    "seed = 42069\n",
    "device = 'cuda:0'\n",
    "num_workers = 0\n",
    "\n",
    "experiment_name = create_experiment_name(method, dataset, config[method][dataset])\n",
    "experiment_name = 'tmp'\n",
    "print(f'Experiment : {experiment_name}')\n",
    "\n",
    "writer = SummaryWriter(os.path.join('logs', experiment_name))\n",
    "\n",
    "set_state(seed)\n",
    "client_params = config[method][dataset]['clients']\n",
    "clients = get_clients(\n",
    "    train_ds, \n",
    "    num_workers=num_workers,\n",
    "    seed=seed,\n",
    "    device=device,\n",
    "    **client_params,\n",
    ")\n",
    "\n",
    "model = CNN()\n",
    "# client optimizer\n",
    "# client_optimizer_cls = torch.optim.SGD\n",
    "# client_optimizer_params = {\n",
    "#     'lr': 0.1,\n",
    "# }\n",
    "client_optimizer_cls = getattr(torch.optim, config[method][dataset]['client_optimizer'])\n",
    "client_optimizer_params = config[method][dataset]['client_optimizer_params']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fed_params = config[method][dataset]['federater']\n",
    "fed_params['seed'] = seed\n",
    "# fed_params = {\n",
    "#     'seed': seed,\n",
    "#     'C': 0.1,\n",
    "# }\n",
    "num_rounds = 1#config[method][dataset]['fit']['num_rounds']\n",
    "num_epochs = 1#config[method][dataset]['fit']['num_epochs']\n",
    "\n",
    "federater = FedAvg(model,\n",
    "                    clients=clients,\n",
    "                    client_optimizer_cls=client_optimizer_cls,\n",
    "                    client_optimizer_params=client_optimizer_params,\n",
    "                    **fed_params)\n",
    "federater.fit(num_rounds=num_rounds, criterion=criterion, num_epochs=num_epochs, val_dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "45d30976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fedprox baseline\n",
    "method = 'fedprox'\n",
    "dataset = 'mnist'\n",
    "seed = 42069\n",
    "device = 'cuda:0'\n",
    "num_workers = 0\n",
    "\n",
    "experiment_name = create_experiment_name(method, dataset, config[method][dataset])\n",
    "experiment_name = 'tmp_prox'\n",
    "print(f'Experiment : {experiment_name}')\n",
    "\n",
    "writer = SummaryWriter(os.path.join('logs', experiment_name))\n",
    "\n",
    "set_state(seed)\n",
    "client_params = config[method][dataset]['clients']\n",
    "clients = get_clients(\n",
    "    train_ds, \n",
    "    num_workers=num_workers,\n",
    "    seed=seed,\n",
    "    device=device,\n",
    "    **client_params,\n",
    ")\n",
    "\n",
    "model = CNN()\n",
    "client_optimizer_cls = getattr(torch.optim, config[method][dataset]['client_optimizer'])\n",
    "client_optimizer_params = config[method][dataset]['client_optimizer_params']\n",
    "server_optimizer = getattr(torch.optim, config[method][dataset]['server_optimizer'])\n",
    "server_optimizer = server_optimizer(model.parameters(), **config[method][dataset]['server_optimizer_params'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fed_params = config[method][dataset]['federater']\n",
    "fed_params['seed'] = seed\n",
    "num_rounds = config[method][dataset]['fit']['num_rounds']\n",
    "num_epochs = config[method][dataset]['fit']['num_epochs']\n",
    "\n",
    "federater = FedProx(model,\n",
    "                   clients=clients,\n",
    "                    server_optimizer=server_optimizer,\n",
    "                   client_optimizer_cls=client_optimizer_cls,\n",
    "                   client_optimizer_params=client_optimizer_params,\n",
    "                   **fed_params)\n",
    "federater.fit(num_rounds=num_rounds, criterion=criterion, num_epochs=num_epochs, val_dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6cfbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fed avg baseline\n",
    "method = 'fedavg'\n",
    "dataset = 'mnist'\n",
    "seed = 42069\n",
    "device = 'cuda:0'\n",
    "num_workers = 0\n",
    "\n",
    "experiment_name = create_experiment_name(method, dataset, config[method][dataset])\n",
    "experiment_name = 'tmp'\n",
    "print(f'Experiment : {experiment_name}')\n",
    "\n",
    "writer = SummaryWriter(os.path.join('logs', experiment_name))\n",
    "\n",
    "set_state(seed)\n",
    "client_params = config[method][dataset]['clients']\n",
    "clients = get_clients(\n",
    "    train_ds, \n",
    "    num_workers=num_workers,\n",
    "    seed=seed,\n",
    "    device=device,\n",
    "    **client_params,\n",
    ")\n",
    "\n",
    "model = CNN()\n",
    "# client optimizer\n",
    "# client_optimizer_cls = torch.optim.SGD\n",
    "# client_optimizer_params = {\n",
    "#     'lr': 0.1,\n",
    "# }\n",
    "client_optimizer_cls = getattr(torch.optim, config[method][dataset]['client_optimizer'])\n",
    "client_optimizer_params = config[method][dataset]['client_optimizer_params']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fed_params = config[method][dataset]['federater']\n",
    "fed_params['seed'] = seed\n",
    "# fed_params = {\n",
    "#     'seed': seed,\n",
    "#     'C': 0.1,\n",
    "# }\n",
    "num_rounds = 1#config[method][dataset]['fit']['num_rounds']\n",
    "num_epochs = 1#config[method][dataset]['fit']['num_epochs']\n",
    "\n",
    "federater = FedAvg(model,\n",
    "                    clients=clients,\n",
    "                    client_optimizer_cls=client_optimizer_cls,\n",
    "                    client_optimizer_params=client_optimizer_params,\n",
    "                    **fed_params)\n",
    "federater.fit(num_rounds=num_rounds, criterion=criterion, num_epochs=num_epochs, val_dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "56ba968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "495dd562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 73403.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57 46 35 28 40 41 44 40 40 47 35 40 39 36 33 50 40 42 41 41 45 54 51 45\n",
      " 41 50 35 32 49 43 44 42 39 55 46 46 53 38 41 50 28 39 46 46 46 45 36]\n",
      "[57 46 35 28 40 41 44 40 40 47 35 40 39 36 33 50 40 42 41 41 45 54 51 45\n",
      " 41 50 35 32 49 43 44 42 39 55 46 46 53 38 41 50 28 39 46 46 46 45 36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import emnist\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "from os.path import dirname\n",
    "\n",
    "similarity = 1\n",
    "num_of_users = 100\n",
    "samples_num = 20\n",
    "dataset = 'balanced'\n",
    "images, train_labels = emnist.extract_training_samples(dataset)  # TODO: add test samples\n",
    "images = np.reshape(images, (images.shape[0], -1))\n",
    "images = images.astype(np.float32)\n",
    "train_labels = train_labels.astype(np.int)\n",
    "num_of_labels = len(set(train_labels))\n",
    "\n",
    "emnist_data = []\n",
    "for i in range(min(train_labels), num_of_labels + min(train_labels)):\n",
    "    idx = train_labels == i\n",
    "    emnist_data.append(images[idx])\n",
    "\n",
    "iid_samples = int(similarity * samples_num)\n",
    "X = [[] for _ in range(num_of_users)]\n",
    "y = [[] for _ in range(num_of_users)]\n",
    "idx = np.zeros(num_of_labels, dtype=np.int64)\n",
    "\n",
    "# create %similarity of iid data\n",
    "for user in range(num_of_users):\n",
    "    labels = np.random.randint(0, num_of_labels, iid_samples)\n",
    "    for label in labels:\n",
    "        X[user].append(emnist_data[label][idx[label]].tolist())\n",
    "        y[user] += (label * np.ones(1)).tolist()\n",
    "        idx[label] += 1\n",
    "\n",
    "print(idx)\n",
    "\n",
    "# fill remaining data\n",
    "for user in range(num_of_users):\n",
    "    label = user % num_of_labels\n",
    "    X[user] += emnist_data[label][idx[label]:idx[label] + samples_num - iid_samples].tolist()\n",
    "    y[user] += (label * np.ones(samples_num - iid_samples)).tolist()\n",
    "    idx[label] += samples_num - iid_samples\n",
    "\n",
    "print(idx)\n",
    "\n",
    "train_data = {'users': [], 'user_data': {}, 'num_samples': []}\n",
    "test_data = {'users': [], 'user_data': {}, 'num_samples': []}\n",
    "\n",
    "for i in trange(num_of_users, ncols=120):\n",
    "    uname = 'f_{0:05d}'.format(i)\n",
    "\n",
    "    combined = list(zip(X[i], y[i]))\n",
    "    random.shuffle(combined)\n",
    "    X[i][:], y[i][:] = zip(*combined)\n",
    "    num_samples = len(X[i])\n",
    "    train_len = int(0.9 * num_samples)\n",
    "    test_len = num_samples - train_len\n",
    "\n",
    "    train_data['users'].append(uname)\n",
    "    train_data['user_data'][uname] = {'x': X[i][:train_len], 'y': y[i][:train_len]}\n",
    "    train_data['num_samples'].append(train_len)\n",
    "    test_data['users'].append(uname)\n",
    "    test_data['user_data'][uname] = {'x': X[i][train_len:], 'y': y[i][train_len:]}\n",
    "    test_data['num_samples'].append(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857bb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4e37c9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "93d7f8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['user_data']['f_00000']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701df02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fedprox baseline\n",
    "method = 'fedopt'\n",
    "dataset = 'mnist'\n",
    "seed = 42069\n",
    "device = 'cuda:0'\n",
    "num_workers = 0\n",
    "\n",
    "experiment_name = create_experiment_name(method, dataset, config[method][dataset])\n",
    "experiment_name = 'tmp'\n",
    "print(f'Experiment : {experiment_name}')\n",
    "\n",
    "writer = SummaryWriter(os.path.join('logs', experiment_name))\n",
    "\n",
    "set_state(seed)\n",
    "client_params = config[method][dataset]['clients']\n",
    "clients = get_clients(\n",
    "    train_ds, \n",
    "    num_workers=num_workers,\n",
    "    seed=seed,\n",
    "    device=device,\n",
    "    **client_params,\n",
    ")\n",
    "\n",
    "model = CNN()\n",
    "client_optimizer_cls = getattr(torch.optim, config[method][dataset]['client_optimizer'])\n",
    "client_optimizer_params = config[method][dataset]['client_optimizer_params']\n",
    "server_optimizer = getattr(torch.optim, config[method][dataset]['server_optimizer'])\n",
    "server_optimizer = server_optimizer(model.parameters(), **config[method][dataset]['server_optimizer_params'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fed_params = config[method][dataset]['federater']\n",
    "fed_params['seed'] = seed\n",
    "num_rounds = config[method][dataset]['fit']['num_rounds']\n",
    "num_epochs = config[method][dataset]['fit']['num_epochs']\n",
    "\n",
    "federater = FedProx(model,\n",
    "                   clients=clients,\n",
    "                    server_optimizer=server_optimizer,\n",
    "                   client_optimizer_cls=client_optimizer_cls,\n",
    "                   client_optimizer_params=client_optimizer_params,\n",
    "                   **fed_params)\n",
    "federater.fit(num_rounds=num_rounds, criterion=criterion, num_epochs=num_epochs, val_dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b3c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
